{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivansst773/Aprendizaje_de_Maquina/blob/main/1_Probabildades_Bayes/1_TAM_ConceptosBasicos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios Capítulo 1 - Teoría de Aprendizaje de Máquina\n",
        "\n",
        "Elaborado por: Andrés Marino Álvarez Meza, amalvarezme@unal.edu.co"
      ],
      "metadata": {
        "id": "9q_77PYmamwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio regresores\n",
        "\n",
        " - Genere datos sintéticos a partir de un tono. senoidal, contaminado con ruido blanco Gaussiano para $SNR_{dB}=\\{1,2,5,10\\} [dB].$\n",
        "\n",
        " - Entrene y pruebe los modelos de regresión por mínimos cuadrados (regularizado con norma L2), log verosimilitud y Máximo a posteriori (prior y ruido Gaussianos), utilizando el $80\\%$ de los datos para entrenar y el $20\\%$ para evaluar.\n",
        "\n",
        "## Relación señal ruido - Signal to Noise Ratio (SNR)\n",
        "\n",
        "\n",
        "$P_x = \\frac{1}{T}\\int |x(t)|^2 dt$ : potencia de la señal.\n",
        "\n",
        "$P_\\eta = \\frac{1}{T}\\int |\\eta(t)|^2 dt$ : potencia del ruido.\n",
        "\n",
        "La SNR se define como:\n",
        "\n",
        "$SNR = \\frac{P_x}{P_\\eta}$\n",
        "\n",
        "En decibeles:\n",
        "\n",
        "$SNR_{dB}  = 10\\log_{10}\\left(\\frac{P_x}{P_\\eta}\\right) \\quad [dB]$\n",
        "\n",
        "Para pasar de $SNR_{dB}$ a SNR:\n",
        "\n",
        "$SNR = 10^{\\frac{SNR_{dB}}{10}} =  \\frac{P_x}{P_\\eta}$\n",
        "\n",
        "\n",
        "Para el caso de ruido blanco Guassiano:\n",
        "\n",
        "$\n",
        "\\eta \\sim p(\\eta) = \\mathscr{G}(\\eta|0,\\sigma_\\eta^2)\n",
        "$\n",
        "\n",
        "Dado que $\\mu_\\eta = 0$:\n",
        "\n",
        "$\\sigma_\\eta^2 = \\mathbb{E}\\{(\\eta-\\mu_\\eta)^2\\} = \\mathbb{E}\\{\\eta^2\\} $\n",
        "\n",
        "Utilizando estimador de media muestral:\n",
        "\n",
        "$\\sigma_{\\eta}^{2}=\\frac{1}{N}\\sum_\\limits{\\eta} \\eta^2$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "$\\sigma_{\\eta}^{2} = P_\\eta = \\frac{P_x}{SNR} =  \\frac{P_x}{ 10^{\\frac{SNR_{dB}}{10}}}$"
      ],
      "metadata": {
        "id": "kl5k3pxlaoKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#función cálculo varianza del ruido a partir del snr dB\n",
        "def var_snr(x,snrdB): #x vector de datos (señal), snrdB SNR en dB\n",
        "    Px = np.mean(x**2)#estimador potencia media de la señal\n",
        "    return Px/(10**(snrdB/10))"
      ],
      "metadata": {
        "id": "xWUiwuZYBL7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se construyen los datos a partir del modelo:\n",
        "\n",
        "$t_n = A\\sin(2\\pi F_o x_n) + \\eta_n$\n",
        "\n",
        "con:\n",
        "\n",
        "$x_n \\in [0,T_o]$\n",
        "\n",
        "$T_o=1/F_o$\n",
        "\n",
        "$\\eta \\sim \\mathscr{G}(\\eta_n|0,\\sigma^2_\\eta)$"
      ],
      "metadata": {
        "id": "MF-eWzE1Cts5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datos simulados\n",
        "Fo = 60 #frecuencia fundamental señal cos\n",
        "A = 10 # amplitud de la señal\n",
        "To = 1/Fo #periodo fundamental\n",
        "Fs = 100*Fo #frecuencia muestreo según nyquist Fs >= 2 Fo\n",
        "X = np.arange(0,To,1/Fs) #vector de entrada en un periodo con pasos según período de muestreo\n",
        "\n",
        "snrdB = 10 #ruido según SNR dB\n",
        "#señal limpia - objetivo\n",
        "tt = A*np.sin(2*np.pi*Fo*X)\n",
        "#modelo con función sinoidal contaminada con ruido Gaussiano\n",
        "t = A*np.sin(2*np.pi*Fo*X) + np.sqrt(var_snr(tt,snrdB))*np.random.randn(len(X))\n",
        "\n",
        "X = X.reshape(-1,1)#filas = realizaciones-muestras\n",
        "t = t.reshape(-1,1)\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P6KQ8DSDCc4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solución por mínimos cuadrados:\n",
        "\n",
        "Se asume mapeo $\\phi:\\mathbb{R}^P\\to\\mathbb{R}^Q$, con $Q\\geq P.$\n",
        "\n",
        "Dado el conjunto de datos $\\{\\phi(\\mathbf{x}_n) \\in \\mathbb{R}^Q, t_n \\in \\mathbb{R}\\}_{n=1}^N,$ podemos definir el modelo lineal:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\mathbf{w}\\in\\mathbb{R}^Q$\n",
        "\n",
        "## Estimador por mínimos cuadrados:\n",
        "\n",
        "El estimador generalizado de mínimos cuadrados con regularización L2 (también conocido como modelo lineal rígido - linear ridge regression), se puede plantear como:\n",
        "\n",
        "$$\\mathbf{w}_{MC2} = \\arg\\min_{\\mathbf{w}} \\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 + \\lambda \\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "con:\n",
        "\n",
        "$\\mathbf{t} = [t_1,t_2,\\cdots,t_n]^\\top\\in\\mathbb{R}^N$\n",
        "\n",
        "$\\pmb{\\Phi}=[\\phi(\\mathbf{x}_1),\\phi(\\mathbf{x}_2),\\cdots,\\phi(\\mathbf{x}_N)]^\\top\\in\\mathbb{R}^{N\\times Q}$\n",
        "\n",
        "$\\lambda\\in\\mathbb{R}^{+}$\n",
        "\n",
        "Derivando e igualando a cero para encotrar el mínimo de la función de costo, tenemos que:\n",
        "\n",
        "$$\\mathbf{w}_{mc} = \\left(\\pmb{\\Phi}^\\top \\pmb{\\Phi}+\\lambda\\mathbf{I_Q}\\right)^{-1}\\pmb{\\Phi}^\\top \\mathbf{t}$$\n",
        "\n",
        "$\\mathbf{I}_Q$: matriz identidad de tamaño $Q$.\n",
        "\n"
      ],
      "metadata": {
        "id": "x-aH4dlyFnxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solución min cuadrados regularizados\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "#generación representación polinomial\n",
        "#desde la libreria sklearn\n",
        "Q = 4#grado del polinomio\n",
        "phiQ = PolynomialFeatures(degree=Q)\n",
        "Phi = phiQ.fit_transform(X)#representar datos desde polinomio\n",
        "\n",
        "#particionar datos\n",
        "rs = ShuffleSplit(n_splits=1, random_state=0, test_size=0.2)\n",
        "for i, (train_i, test_i) in enumerate(rs.split(X)):\n",
        "   print(i)\n",
        "\n",
        "\n",
        "#regresor\n",
        "lambdaR = 1e-15#hiperparámetro de regularización\n",
        "reg_mc = Ridge(alpha=lambdaR)\n",
        "\n",
        "train_i = np.sort(train_i)\n",
        "test_i = np.sort(test_i)\n",
        "\n",
        "reg_mc.fit(Phi[train_i],t[train_i])\n",
        "\n",
        "t_mc = reg_mc.predict(Phi[test_i])\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{mcr}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "# plt.figure(figsize=(5,3))\n",
        "# plt.stem(reg_mc.coef_[0])\n",
        "# plt.ylabel('pesos')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "aGPjIlB5OFfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementando solución por svd"
      ],
      "metadata": {
        "id": "5VRCSIiWbUkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regsvd(Phi,t,lambdaR=0,tol=1e-16):\n",
        "  S = Phi.T.dot(Phi) + lambdaR*np.eye(Phi.shape[1])\n",
        "  val,vec = np.linalg.eigh(S)\n",
        "  print(val.shape,vec.shape)\n",
        "  ind = val > tol #valores propios mayores a 0\n",
        "  Sinv = vec[:,ind].dot(np.diag(1/val[ind])).dot(vec[:,ind].T)\n",
        "  return Sinv.dot(Phi.T.dot(t)),val\n"
      ],
      "metadata": {
        "id": "_rfLTOf0bWqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wml,val = regsvd(Phi[train_i],t[train_i],lambdaR=lambdaR)\n",
        "\n",
        "t_mc = Phi[test_i].dot(wml)\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{mcr}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(val)\n",
        "plt.ylabel('eigenvalue')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(wml)\n",
        "plt.ylabel('pesos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zvF6WZNc4lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictiva desde máxima verosimilitud\n",
        "\n",
        "Para el caso de ruido blanco Gaussiano, tenemos que:\n",
        "\n",
        "$\\eta_n \\sim p(\\eta_n) = \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$\n",
        "\n",
        "con:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\eta_n = t_n - \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top$\n",
        "\n",
        "Por lo tanto:\n",
        "\n",
        "$p(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2)$\n",
        "\n",
        "Podemos encontrar los pesos y la varianza maximizando el log-verosimilitud:\n",
        "\n",
        "$$\\mathbf{w}_{ML} = \\arg\\max_{\\mathbf{w},\\sigma_\\eta^2} \\log\\left(\\prod_{n=1}^N\\mathscr{G}(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2)\\right)$$\n",
        "\n",
        "Asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{ML},\\sigma_{ML}^2 = \\arg\\max_{\\mathbf{w},\\sigma_\\eta^2} -\\frac{N}{2}\\log(2\\pi)-\\frac{N}{2}\\log(\\sigma_\\eta^2)-\\frac{1}{2\\sigma^2}\\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2$$\n",
        "\n",
        "Derivando respecto a las variables de interés, e igualando a 0:\n",
        "\n",
        "$$\\sigma^2_{ML} = \\frac{1}{N}\\sum_\\limits{n=1}^N\\left(t_n-\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top\\right)^2$$\n",
        "\n",
        "$$\\mathbf{w}_{ML} = \\left(\\pmb{\\Phi}^\\top \\pmb{\\Phi}\\right)^{-1}\\pmb{\\Phi}^\\top \\mathbf{t}$$\n",
        "\n",
        "\n",
        "La fdp predictiva, para un nuevo dato $\\mathbf{x}_*$, se puede estimar como:\n",
        "\n",
        "$$p(t_*|\\mathbf{x}_*,\\mathbf{t},\\pmb{\\Phi},\\mathbf{w}_{ML},\\sigma^2_{ML})=\\mathscr{G}(t_*|\\phi(\\mathbf{x}_*)\\mathbf{w}_{ML}^\\top,\\sigma_{ML}^2)$$"
      ],
      "metadata": {
        "id": "kGpHK3jvfo-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gráfica estimación con predictiva en ML:\n",
        "var_ml = (np.linalg.norm(t[train_i]-reg_mc.predict(Phi[train_i]))**2)/len(t[train_i])\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t$')\n",
        "plt.scatter(X,t,c='b',label='$t+\\eta$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{*}$')\n",
        "plt.fill_between(X[test_i].ravel(), t_mc.ravel() - np.sqrt(var_ml)*np.ones(len(t_mc)),\n",
        "                t_mc.ravel() + np.sqrt(var_ml)*np.ones(len(t_mc)), alpha=0.2)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "print(var_ml)"
      ],
      "metadata": {
        "id": "wyqcgzl8jubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Teorema del límite central\n",
        "\n",
        "Sea $x_n \\sim p(x_n)$ una variable aleatoria con fdp $p(x_n)$.\n",
        "\n",
        "La combinación:\n",
        "\n",
        "$a_0 x_0+a_1x_1+a_2x_2+ \\cdots a_N x_N \\sim \\mathscr{G}(\\sum_n a_n x_n | \\mu_,\\sigma^2)$\n",
        "\n",
        "Siendo $\n",
        "\\mathscr{G}$ una fdp Gaussiana.\n",
        "## Ejemplo\n",
        "\n",
        "Sea $x\\sim \\mathscr{U}(x|0,1)$ una variable aleatoria con fdp Uniforme. Mediante una simulación de Monte-Carlo de 1000 repeticiones, encuentre la estimación por histograma de la fdp de la media muestral $x$, con base al muestreo desde la fdp Uniforme con $N\\in\\{1.2.10\\}$ datos."
      ],
      "metadata": {
        "id": "genhr8rEReJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mofc88lCRdUq"
      },
      "outputs": [],
      "source": [
        "#simulación del teorema del límite central\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#posibles cantidades de datos\n",
        "N = np.array([1,2,10])\n",
        "#repeticiones del experimento - simulación de monte carlo\n",
        "M = 1000\n",
        "mlc = np.zeros((M,len(N)))\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "for i in range(len(N)):#recorrer cantidad de muestras\n",
        "    for j in range(M): #recorrer iteraciones de monte carlo\n",
        "        xdata = np.random.rand(N[i])#simulamos datos desde una fdp uniforme\n",
        "        mlc[j,i] = xdata.mean() #estimación media muestral x\n",
        "    plt.hist(mlc[:,i],bins=8, label='N='+str(N[i]),density=True, alpha=0.5) #graficar histograma\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('$\\hat{\\mu}(x)$')\n",
        "plt.ylabel('$\\hat{p}(\\hat{\\mu}(x))$')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guassianas condicionales y máximo a posteriori\n",
        "\n",
        "Para resolver el regresor Bayesiano completo, necesitamos encontrar la probabilidad condicional dado una probabilidad conjunta Gaussiana.\n",
        "\n",
        "Para el caso del máximo a posteriori, desde el teorema de Bayes, tenemos que (se simplifica el modelo en función de la salida y los pesos para facilitar la notación):\n",
        "\n",
        "$p(\\mathbf{t},\\mathbf{w})=p(\\mathbf{w},\\mathbf{t})$\n",
        "\n",
        "$p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})=p(\\mathbf{w}|\\mathbf{t})p(\\mathbf{t})$\n",
        "\n",
        "El posterior $p(\\mathbf{w}|\\mathbf{t})$ se puede encontrar como:\n",
        "\n",
        "$$p(\\mathbf{w}|\\mathbf{t})=\\frac{p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathbf{t})}$$\n",
        "\n",
        "con evidencia:\n",
        "\n",
        "\n",
        "$p(\\mathbf{t})=\\int p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w}) d\\mathbf{w}$\n",
        "\n",
        "Para el caso de ruido y pesos modelados mediante fdp Gaussinas:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\eta_n \\sim p(\\eta_n)= \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$\n",
        "\n",
        "$\\eta_n = t_n - \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top$\n",
        "\n",
        "Por lo tanto:\n",
        "\n",
        "$p(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}\\left(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)$\n",
        "\n",
        "Además:\n",
        "\n",
        "$p(\\mathbf{w})= \\mathscr{G}(\\mathbf{w}|0,\\sigma_w^2\\mathbf{I}_Q)$\n",
        "\n",
        "El modelo por máximo a-posteriori, simplifica la relación de Bayes mediante la proporcionalidad:\n",
        "\n",
        "$p(\\mathbf{w}|\\mathbf{t}) \\propto p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})$\n",
        "\n",
        "Por consiguiente, asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\max_{\\mathbf{w}} \\log\\left(\\prod_{n=1}^N\\mathscr{G}\\left(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)\\prod_{q=1}^Q \\mathscr{G}({w}_q|0,\\sigma_w^2)\\right)$$\n",
        "\n",
        "Asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\max_{\\mathbf{w}} -\\frac{1}{2\\sigma_\\eta^2}\\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 - \\frac{1}{2\\sigma_w^2}\\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "Teniendo en cuenta que los factores de escala no modifican el punto mínimo/máximo en la optmización, podemos factorizar el problema equivalente MAP como:\n",
        "\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\min_{\\mathbf{w}} \\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 + \\frac{\\sigma^2_\\eta}{\\sigma_w^2}\\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "Bajo estas suposiciones, el problema de optimización de MAP asumiendo ruido y prior Gaussianos, es equivalente a la optimización de mínimos cuadrados regularizados con $\\lambda=\\frac{\\sigma^2_\\eta}{\\sigma_w^2}.$\n",
        "\n",
        "Ahora, analizando un modelo lineal Gaussiano desde la conjunta:\n",
        "\n",
        "\n",
        "$\\mathbf{z} = [\\mathbf{x}_a,\\mathbf{x}_b] \\sim \\mathscr{G}(\\mathbf{z}|\\pmb{\\mu},\\mathbf{\\Sigma})$\n",
        "\n",
        "tenemos que:\n",
        "\n",
        "$p(\\mathbf{x}_a|\\mathbf{x}_b)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a|b},\\mathbf{\\Sigma}_{a|b})$\n",
        "\n",
        "\n",
        "donde:\n",
        "\n",
        "$\\pmb{\\mu}_{a|b}=\\pmb{\\mu}_{a}+\\mathbf{\\Sigma}_{ab}\\mathbf{\\Sigma}_{bb}^{-1}(\\mathbf{x}_b - \\pmb{\\mu}_b)$\n",
        "\n",
        "$\\mathbf{\\Sigma}_{a|b} = \\mathbf{\\Sigma}_{aa}-\\mathbf{\\Sigma}_{ab}\\mathbf{\\Sigma}_{bb}^{-1}\\mathbf{\\Sigma}_{ba}$\n",
        "\n",
        "y\n",
        "\n",
        "$p(\\mathbf{x}_a)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a},\\mathbf{\\Sigma}_{aa})$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OyO5m3A4-vDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo:\n",
        "\n",
        "Sea la variable aleatoria $\\mathbf{z} = [x_a,x_b]\\sim \\mathscr{G}(\\mathbf{z}|\\pmb{\\mu},\\mathbf{\\Sigma})$, con:\n",
        "\n",
        "$$\\pmb{\\mu} = [\\mu_a,\\mu_b] = [0.5,0.2]$$\n",
        "\n",
        "$$\\pmb{\\Sigma}= \\begin{bmatrix} \\sigma_a^2 & \\sigma_{ab}\\\\ \\sigma_{ba} & \\sigma^2_{b}\\end{bmatrix} = \\begin{bmatrix} 0.8 & 0.3\\\\ 0.3 & 0.6\\end{bmatrix} $$\n",
        "\n",
        "\n",
        "Encuentre y grafique $p(\\mathbf{x}_a)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a},\\mathbf{\\Sigma}_{aa})$ y $p(\\mathbf{x}_a|\\mathbf{x}_b)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a|b},\\mathbf{\\Sigma}_{a|b})$"
      ],
      "metadata": {
        "id": "xejKIJlLUo6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multivariate_normal as mn\n",
        "#simulamos la fdp conjunta\n",
        "N = 100\n",
        "muC = np.array([0.5,0.2])\n",
        "SigmaC = np.array([[0.8,0.3],[0.3,0.6]])\n",
        "pdfC = mn(muC, SigmaC)\n",
        "Xd = pdfC.rvs(size=N)\n",
        "pC = pdfC.pdf(Xd)\n",
        "\n",
        "#meshgrid contornos\n",
        "h = 0.02\n",
        "x_min, x_max = Xd[:, 0].min() - np.std(Xd[:, 0]), Xd[:, 0].max() + np.std(Xd[:, 0])\n",
        "y_min, y_max = Xd[:, 1].min() - np.std(Xd[:, 1]), Xd[:, 1].max() + np.std(Xd[:, 1])\n",
        "xx, yy = np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)\n",
        "\n",
        "X = np.linspace(x_min, x_max, round(0.5*N))\n",
        "Y = np.linspace(y_min, y_max, round(0.5*N))\n",
        "X, Y = np.meshgrid(X, Y)\n",
        "\n",
        "\n",
        "# Pack X and Y into a single 3-dimensional array\n",
        "pos = np.empty(X.shape + (2,))\n",
        "pos[:, :, 0] = X\n",
        "pos[:, :, 1] = Y\n",
        "\n",
        "# evaluar pdf conjunta\n",
        "Z = pdfC.pdf(pos)\n",
        "\n",
        "#x_b = 2\n",
        "xb = 2\n",
        "#contornos\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.contour(X, Y, Z,levels=20)\n",
        "#scatter\n",
        "plt.scatter(Xd[:,0],Xd[:,1],c='r')\n",
        "plt.plot(np.linspace(x_min,x_max,50),xb*np.ones((50,1)),c='g')\n",
        "plt.grid()\n",
        "plt.xlabel('$x_a$')\n",
        "plt.ylabel('$x_b$')\n",
        "plt.title('$p(x_a,x_b)$')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#probabilidad marginal de x_a\n",
        "mu_a = 0.5\n",
        "Sigma_a = 0.8\n",
        "pdf_a = mn(mu_a, Sigma_a)\n",
        "X_a = np.linspace(1.25*x_min,1.25*x_max,N)\n",
        "p_a = pdf_a.pdf(X_a)\n",
        "\n",
        "#probabilidad condicional x_a | x_b = 2\n",
        "mu_b = 0.2\n",
        "Sigma_ab = 0.3\n",
        "Sigma_ba = Sigma_ab\n",
        "Sigma_b = 0.6\n",
        "\n",
        "mu_alb = mu_a+Sigma_ab*Sigma_b**(-1)*(xb - mu_b)\n",
        "Sigma_alb = Sigma_a-Sigma_ab*Sigma_b**(-1)*Sigma_ba\n",
        "pdf_alb = mn(mu_alb, Sigma_alb)\n",
        "p_alb = pdf_alb.pdf(X_a)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X_a,p_a,label='$p(x_a)$')\n",
        "plt.plot(X_a,p_alb,label='$p(x_a|x_b=2)$')\n",
        "plt.xlabel('$x_a$')\n",
        "plt.ylabel('fdp')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wPnLSd3IgXwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo lineal Gaussiano\n",
        "\n",
        "Sea el prior:\n",
        "\n",
        "$p(\\mathbf{x})=\\mathscr{G}(\\mathbf{x}|\\pmb{\\mu},\\pmb{\\Lambda}^{-1})$\n",
        "\n",
        "Además, sea la verosimilitud desde un modelo lineal $\\mathbf{y} = \\mathbf{A}\\mathbf{x}+\\mathbf{b}$:\n",
        "\n",
        "$p(\\mathbf{y}|\\mathbf{x})=\\mathscr{G}(\\mathbf{y}|\\mathbf{A}\\mathbf{x}+\\mathbf{b},\\mathbf{L}^{-1})$\n",
        "\n",
        "Completando cuadrados sobre la Gaussiana conjunta, tenemos que:\n",
        "\n",
        "$p(\\mathbf{y})=\\mathscr{G}(\\mathbf{y}|\\mathbf{A}\\pmb{\\mu}+\\mathbf{b},\\mathbf{L}^{-1}+\\mathbf{A}\\pmb{\\Lambda}^{-1}\\mathbf{A}^\\top)$\n",
        "\n",
        "$p(\\mathbf{x}|\\mathbf{y})=\\mathscr{G}(\\mathbf{y}|\\pmb{\\mu}_{x|y},\\mathbf{\\Sigma}_{x|y})$\n",
        "\n",
        "con:\n",
        "\n",
        "$\\pmb{\\mu}_{x|y} = \\mathbf{\\Sigma}_{x|y}\\left(\\mathbf{A}^\\top\\mathbf{L}(\\mathbf{y}-\\mathbf{b})+\\pmb{\\Lambda}\\pmb{\\mu}\\right)$\n",
        "\n",
        "$\\mathbf{\\Sigma}_{x|y} = \\left(\\pmb{\\Lambda}+\\mathbf{A}^\\top\\mathbf{L}\\mathbf{A}\\right)^{-1}$\n",
        "\n",
        "Para el caso del modelo de regresión:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\eta_n \\sim p(\\eta_n)= \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$\n",
        "\n",
        "$\\eta_n = t_n - \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top$\n",
        "\n",
        "Por lo tanto, la verosimilitud se puede escribir como:\n",
        "\n",
        "$p(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}\\left(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)$\n",
        "\n",
        "En forma vectorial:\n",
        "\n",
        "$p(\\mathbf{t}|\\pmb{\\Phi}\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}\\left(\\mathbf{t}|\\pmb{\\Phi}\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)$\n",
        "\n",
        "Asumiendo el prior:\n",
        "\n",
        "$p(\\mathbf{w}) = \\mathscr{G}(\\mathbf{w}|\\mathbf{m}_o,\\mathbf{S}_o)$\n",
        "\n",
        "El posterior se puede estimar como:\n",
        "\n",
        "$p(\\mathbf{w}|\\mathbf{t}) = \\mathscr{G}(\\mathbf{w}|\\mathbf{m}_N,\\mathbf{S}_N)$\n",
        "\n",
        "donde:\n",
        "\n",
        "$\\mathbf{m}_N = \\mathbf{S}_N\\left(\\mathbf{S}_o^{-1}\\mathbf{m}_o + \\frac{1}{\\sigma_\\eta^2}\\pmb{\\Phi}^\\top\\mathbf{t}\\right)$\n",
        "\n",
        "$\\mathbf{S}_N = \\left(\\mathbf{S}_o^{-1} + \\frac{1}{\\sigma_\\eta^2}\\pmb{\\Phi}^\\top\\pmb{\\Phi}\\right)^{-1}$\n",
        "\n",
        "Si se impone un prior de la forma:\n",
        "\n",
        "$p(\\mathbf{w}) = \\mathscr{G}(\\mathbf{w}|0,\\sigma_w^2)$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "$p(\\mathbf{w}|\\mathbf{t}) = \\mathscr{G}(\\mathbf{w}|\\tilde{\\mathbf{m}}_N,\\tilde{\\mathbf{S}}_N)$\n",
        "\n",
        "\n",
        "$\\tilde{\\mathbf{m}}_N = \\frac{1}{\\sigma_\\eta^2} \\tilde{\\mathbf{S}}_N\\pmb{\\Phi}^\\top\\mathbf{t}$\n",
        "\n",
        "$\\tilde{\\mathbf{S}}_N = \\left(\\frac{1}{\\sigma_w^2}\\mathbf{I}_Q + \\frac{1}{\\sigma_\\eta^2}\\pmb{\\Phi}^\\top\\pmb{\\Phi}\\right)^{-1} = \\left(\\frac{1}{\\sigma_\\eta^2}\\right)^{-1}\\left(\\frac{\\sigma_\\eta^2}{\\sigma_w^2}\\mathbf{I}_Q + \\pmb{\\Phi}^\\top\\pmb{\\Phi}\\right)^{-1}$\n",
        "\n",
        "Reemplazando en la media condicional:\n",
        "\n",
        "$\\tilde{\\mathbf{m}}_N = \\frac{1}{\\sigma_\\eta^2} \\left(\\frac{1}{\\sigma_\\eta^2}\\right)^{-1}\\left(\\frac{\\sigma_\\eta^2}{\\sigma_w^2}\\mathbf{I}_Q + \\pmb{\\Phi}^\\top\\pmb{\\Phi}\\right)^{-1}\\pmb{\\Phi}^\\top\\mathbf{t}$\n",
        "\n",
        "\n",
        "$\\tilde{\\mathbf{m}}_N = \\left(\\frac{\\sigma_\\eta^2}{\\sigma_w^2}\\mathbf{I}_Q + \\pmb{\\Phi}^\\top\\pmb{\\Phi}\\right)^{-1}\\pmb{\\Phi}^\\top\\mathbf{t}$\n",
        "\n",
        "**Nota:** la solución del modelo lineal Gaussiano para el prior $p(\\mathbf{w}) = \\mathscr{G}(\\mathbf{w}|0,\\sigma_w^2)$ y ante ruido blanco Gaussiano $\\eta_n \\sim p(\\eta_n)= \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$, es equivalente en la media $\\tilde{\\mathbf{m}}_N$ a la solución de mínimos cuadrados regularizados.\n"
      ],
      "metadata": {
        "id": "AlfXLo7DLPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictiva\n",
        "\n",
        "Para un nuevo dato $\\mathbf{x}_*$, la distribución predictiva referente a la salida $t_*$ se puede calcular como:\n",
        "\n",
        "$p(t_*|\\mathbf{x}_*,\\mathbf{t},\\mathbf{w}) = \\int p(t_*|\\mathbf{x}_*,\\mathbf{w})p(\\mathbf{w}|\\mathbf{t})d\\mathbf{w}$\n",
        "\n",
        "$p(t_*|\\mathbf{t}) = \\int \\mathscr{G}\\left(t_*|\\phi(\\mathbf{x}_*)\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)\\mathscr{G}(\\mathbf{w}|\\tilde{\\mathbf{m}}_N,\\tilde{\\mathbf{S}}_N)d\\mathbf{w}$\n",
        "\n",
        "$p(t_*|\\mathbf{x}_*,\\mathbf{t},\\mathbf{w}) = \\mathscr{G}\\left(t_*|\\phi(\\mathbf{x}_*)\\tilde{\\mathbf{m}}_N^\\top,\\sigma_\\eta^2 + \\phi(\\mathbf{x}_*)\\tilde{\\mathbf{S}}_N \\phi(\\mathbf{x}_*)^\\top\\right)$\n",
        "\n"
      ],
      "metadata": {
        "id": "CXsE4Vq_cZp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio:\n",
        "\n",
        "Implementar simulación para el regresor lineal Gaussiano (Bayesiano), para la señal:\n",
        "\n",
        "Se construyen los datos a partir del modelo:\n",
        "\n",
        "$t_n = A\\sin(2\\pi F_o x_n) + \\eta_n$\n",
        "\n",
        "con:\n",
        "\n",
        "$x_n \\in [0,T_o]$\n",
        "\n",
        "$T_o=1/F_o$\n",
        "\n",
        "$\\eta \\sim \\mathscr{G}(\\eta_n|0,\\sigma^2_\\eta)$\n",
        "\n",
        "Imponga prior Gaussiano isotrópico con media cero.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d5G3yZ8Dhv6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datos simulados\n",
        "Fo = 60 #frecuencia fundamental señal cos\n",
        "A = 1 # amplitud de la señal\n",
        "To = 1/Fo #periodo fundamental\n",
        "Fs = 100*Fo #frecuencia muestreo según nyquist Fs >= 2 Fo\n",
        "X = np.arange(0,To,1/Fs) #vector de entrada en un periodo con pasos según período de muestreo\n",
        "\n",
        "snrdB = 10 #ruido según SNR dB\n",
        "#señal limpia - objetivo\n",
        "tt = A*np.sin(2*np.pi*Fo*X)\n",
        "#modelo con función sinoidal contaminada con ruido Gaussiano\n",
        "t = A*np.sin(2*np.pi*Fo*X) + np.sqrt(var_snr(tt,snrdB))*np.random.randn(len(X))\n",
        "\n",
        "X = X.reshape(-1,1)#filas = realizaciones-muestras\n",
        "t = t.reshape(-1,1)\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KK4BAVy0j5zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento función regresor lineal Gaussiano: posterior\n",
        "def my_linGuassiano(X,t,phiQ,sig_eta,sig_w,tol=1e-16):\n",
        "  Phi = phiQ.fit_transform(X)\n",
        "  lambdaR = sig_eta/sig_w\n",
        "  SNinv = Phi.T.dot(Phi) + lambdaR*np.eye(Phi.shape[1])#covarianza\n",
        "  val,vec = np.linalg.eigh(SNinv)\n",
        "  ind = val > tol #valores propios mayores a 0\n",
        "  SN = vec[:,ind].dot(np.diag(1/val[ind])).dot(vec[:,ind].T)\n",
        "  mN = SN.dot(Phi.T.dot(t)) #estimación media lineal Gaussiano\n",
        "  return mN,SN,val\n",
        "\n",
        "#estimación predictiva modelo lineal Gaussiano\n",
        "def my_predictivaLG(xnew,phiQ,mN,SN,sig_eta):\n",
        "  Phinew = phiQ.fit_transform(xnew) #mapeo polinomio Nnew x Q\n",
        "  mnew = Phinew.dot(mN)\n",
        "  signew = np.diag(sig_eta*np.eye(Phinew.shape[0]) + Phinew.dot(SN).dot(Phinew.T))\n",
        "  return mnew, signew"
      ],
      "metadata": {
        "id": "WqrTsenwivAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generación representación polinomial\n",
        "#desde la libreria sklearn\n",
        "Q = 9#grado del polinomio\n",
        "phiQ = PolynomialFeatures(degree=Q)\n",
        "\n",
        "#particionar datos\n",
        "rs = ShuffleSplit(n_splits=1, random_state=0, test_size=0.2)\n",
        "for i, (train_i, test_i) in enumerate(rs.split(X)):\n",
        "   print(i)\n",
        "train_i = np.sort(train_i)\n",
        "test_i = np.sort(test_i)\n",
        "\n",
        "#regresor lineal Gaussiano\n",
        "sig_eta = 1\n",
        "sig_w = 1e13\n",
        "mN,SN,val = my_linGuassiano(X[train_i],t[train_i],phiQ,sig_eta,sig_w)\n",
        "mnew, signew = my_predictivaLG(X[test_i],phiQ,mN,SN,sig_eta)\n",
        "\n",
        "print(mnew.shape, signew.shape)"
      ],
      "metadata": {
        "id": "xMfIWSCgiWOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t$')\n",
        "plt.scatter(X,t,c='b',label='$t+\\eta$')\n",
        "plt.plot(X[test_i],mnew,c='g',label='$t_{*}$')\n",
        "plt.fill_between(X[test_i].ravel(), mnew.ravel() - signew,\n",
        "                        mnew.ravel() + signew, alpha=0.2)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1D9gnSg7nI8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualización Regresor Bayesiano en Función de los Datos de Entrenamiento\n",
        "\n",
        "Se plantea un modelo de regresión lineal con ruido y prior Gaussianos isotrópicos."
      ],
      "metadata": {
        "id": "LPVBwXLS7G2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar pdf 2D\n",
        "def my_2Dpdf(mu,Sigma,axes,N=100,h=0.02,xlabel_='$w_0$',ylabel_='$w_1$',\n",
        "             cmap = 'Reds',xlim=None,ylim=None):\n",
        "  pdfx = mn(mu, Sigma)\n",
        "  Xx = pdfx.rvs(size=N)\n",
        "  pp = pdfx.pdf(Xx)\n",
        "  #meshgrid contornos\n",
        "  if xlim == None:\n",
        "    x_min, x_max = pdfx.mean[0] - 4*pdfx.cov[0,0], pdfx.mean[0] + 4*pdfx.cov[0,0]\n",
        "  else:\n",
        "    x_min, x_max = xlim[0], xlim[1]\n",
        "  if ylim == None:\n",
        "    y_min, y_max = pdfx.mean[1] - 4*pdfx.cov[1,1], pdfx.mean[1] + 4*pdfx.cov[1,1]\n",
        "  else:\n",
        "    y_min, y_max = ylim[0], ylim[1]\n",
        "  xx, yy = np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)\n",
        "\n",
        "  X = np.linspace(x_min, x_max, round(0.5*N))\n",
        "  Y = np.linspace(y_min, y_max, round(0.5*N))\n",
        "  X, Y = np.meshgrid(X, Y)\n",
        "  # Pack X and Y into a single 3-dimensional array\n",
        "  pos = np.empty(X.shape + (2,))\n",
        "  pos[:, :, 0] = X\n",
        "  pos[:, :, 1] = Y\n",
        "\n",
        "  # evaluar pdf conjunta\n",
        "  Z = pdfx.pdf(pos)\n",
        "  #contornos\n",
        "  axes.contourf(X, Y, Z,levels=20,cmap = cmap)\n",
        "  #axes.grid()\n",
        "  axes.set_xlabel(xlabel_)\n",
        "  axes.set_ylabel(ylabel_)\n",
        "  axes.set_xlim(xlim)\n",
        "  axes.set_xlim(ylim)\n",
        "\n",
        "  #plt.title('$p(x_a,x_b)$')\n",
        "  return\n",
        "\n",
        "def my_linregsyn(mu,Sigma,axes,xmin=-1,xmax=1,Nmod = 10,xlim=[-1.2,1.2],ylim=[-1.2,1.2]):\n",
        "  pdfw = mn(mu, Sigma)\n",
        "  wmod = pdfw.rvs(size=Nmod)\n",
        "  X = np.random.uniform(low=xmin, high=xmax, size=100)\n",
        "  t = wmod.dot(np.r_[X.reshape(1,-1),np.ones((1,X.shape[0]))])\n",
        "  axes.plot(X,t.T,c='b')\n",
        "  axes.set_xlabel('$x$')\n",
        "  axes.set_ylabel('$f(x|w)$')\n",
        "  axes.set_xlim(xlim)\n",
        "  axes.set_ylim(ylim)\n",
        "  return\n",
        "\n",
        "def my_posterior_update(X,t,sig_eta,sig_w,tol=1e-10):\n",
        "  # X in Real N x P\n",
        "  # sig_eta varianza ruido Guassiano\n",
        "  # sig_w varizan prior Gaussiano isotrópico pesos\n",
        "\n",
        "  lambdaR = sig_eta/sig_w\n",
        "  SNinv = X.T.dot(X) + lambdaR*np.eye(X.shape[1])#covarianza\n",
        "  val,vec = np.linalg.eigh(SNinv)\n",
        "  ind = val > tol #valores propios mayores a 0\n",
        "  SN = vec[:,ind].dot(np.diag(1/val[ind])).dot(vec[:,ind].T)\n",
        "  mN = np.squeeze(SN.dot(X.T.dot(t))) #estimación media lineal Gaussiano\n",
        "  return mN,SN #mN SN mean y cov Gaussiana del posterior\n",
        "\n",
        "\n",
        "#estimación predictiva modelo lineal Gaussiano\n",
        "def my_predictiva_update(xnew,mN,SN,sig_eta):\n",
        "  #Phinew = phiQ.fit_transform(xnew) #mapeo polinomio Nnew x Q\n",
        "  mnew = xnew.dot(mN)\n",
        "  signew = np.diag(sig_eta*np.eye(xnew.shape[0]) + xnew.dot(SN).dot(xnew.T))\n",
        "  return mnew, signew"
      ],
      "metadata": {
        "id": "Zxc2P3TMoFys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simular datos regresor lineal + ruido Gaussiano\n",
        "snrdB = 5 #ruido según SNR dB\n",
        "#señal limpia - objetivo\n",
        "N = 500\n",
        "w_ = np.array([-0.8,1.2]) #pesos modelo original\n",
        "X = np.c_[np.random.uniform(low=-1, high=1, size=N).reshape(N,1),np.ones((N,1))]\n",
        "#salida limpia\n",
        "tt = X.dot(w_.T)\n",
        "#modelo con función sinoidal contaminada con ruido Gaussiano\n",
        "sig_eta = var_snr(tt,snrdB)\n",
        "t = tt + np.sqrt(sig_eta)*np.random.randn(X.shape[0])\n",
        "plt.scatter(X[:,0],t,label='$t_n$')\n",
        "plt.plot(X[:,0],tt,'r',label='$t_n^*$')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JEGXfsF-dx5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "#vector muestreo aleatorio datos en X\n",
        "ind = np.random.randint(0,X.shape[0],size=X.shape[0])\n",
        "#definir prior pesos\n",
        "mu_w = np.array([0,0])\n",
        "sig_w = 0.5\n",
        "S_w = sig_w*np.eye(len(mu_w))\n",
        "\n",
        "#limites gráficos\n",
        "wxlim = [-3,3]\n",
        "wylim = [-3,3]\n",
        "xlim = [-1.2,1.2]\n",
        "ylim = [-4,4]\n",
        "\n",
        "\n",
        "\n",
        "#figura y axes animación\n",
        "fig, ax = plt.subplots(2, 3,figsize=(8,5))\n",
        "ax[0,2].axis('off')\n",
        "#función para gráfico interactivo\n",
        "def update(i):\n",
        "    #actualización regresor Bayesiano\n",
        "    #Graficar prior\n",
        "    ax[0,0].clear()\n",
        "    ax[0,1].clear()\n",
        "    ax[1,0].clear()\n",
        "    ax[1,1].clear()\n",
        "    ax[1,2].clear()\n",
        "\n",
        "    my_2Dpdf(mu_w,S_w,axes=ax[0,0],cmap='Reds',xlim=wxlim,ylim=wylim)\n",
        "    #muestreo regresores desde prior\n",
        "    my_linregsyn(mu_w,S_w,axes=ax[0,1],xlim=xlim,ylim=ylim)\n",
        "    #actualizar prior a posterior con 1 dato\n",
        "    mN,SN = my_posterior_update(X[ind[:i]],t[ind[:i]],sig_eta,sig_w,tol=1e-10)\n",
        "    my_2Dpdf(mN,SN,axes=ax[1,0],cmap='Reds',xlim=wxlim,ylim=wylim)\n",
        "    my_linregsyn(mN,SN,axes=ax[1,1],xlim=xlim,ylim=ylim)\n",
        "    ax[1,1].scatter(X[ind[:i],0],t[ind[:i]],c='r',marker='.')\n",
        "    #pesos originales\n",
        "    ax[1,0].scatter(w_[0],w_[1],marker='+',s=60,c='w')\n",
        "    ax[0,0].scatter(w_[0],w_[1],marker='+',s=60,c='w')\n",
        "\n",
        "    #graficar predictiva\n",
        "    mnew,snew = my_predictiva_update(X,mN,SN,sig_eta)\n",
        "    ax[1,2].plot(X[:,0],tt,c='g')\n",
        "    ax[1,2].scatter(X[ind[:i],0],t[ind[:i]],c='r',marker='.')\n",
        "    ax[1,2].plot(X[:,0],mnew,c='b')\n",
        "    ii = np.argsort(X[:,0]) #organizar eje x para visualizar incertidumbre\n",
        "    ax[1,2].fill_between(X[ii,0].ravel(), mnew[ii].ravel() - 2*snew[ii],\n",
        "                        mnew[ii].ravel() + 2*snew[ii], alpha=0.5)\n",
        "    #Limites para visualizar predictiva\n",
        "    ax[1,2].set_xlim(xlim)\n",
        "    ax[1,2].set_ylim(ylim)\n",
        "\n",
        "    #titulos\n",
        "    ax[0,0].set_title('Prior')\n",
        "    ax[0,1].set_title('Prior-Modelos')\n",
        "    ax[1,0].set_title('Posterior ' + str(i) + ' datos' )\n",
        "    ax[1,1].set_title('Posterior-Modelos')\n",
        "    ax[1,2].set_title('Predictiva')\n",
        "    plt.subplots_adjust(wspace=0.7,hspace=0.7)\n",
        "    print(i)\n",
        "\n",
        "\n",
        "\n",
        "#desplegar animación\n",
        "anim = animation.FuncAnimation(fig, update, frames=np.array([0,1,2,3,5,7,9,10,15,20,25,50,100,250,500]), blit=False)\n",
        "rc('animation', html='jshtml')\n"
      ],
      "metadata": {
        "id": "3j9dbZPd9b5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim"
      ],
      "metadata": {
        "id": "oSNkrZHMfu-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio Bonificación Parcial 1 (Hasta 1 unidad)\n",
        "\n",
        "- Presente la animación de actualización del modelo ilustrado en el ejemplo anterior para el estimador de máxima verosimilitud (graficar estimación con incertidumbre).\n",
        "\n",
        "- Repetir el ejemplo de la animación para el estimador Bayesiano para la función senoidal contaminada con ruido Gaussiano utilizando mapeo Polinomial de grado 9.\n",
        "\n",
        "- Incluya la gráfica de la magnitud de los pesos y la matriz covarianza como una imagen.\n",
        "\n",
        "- Para las dos componentes más importentes, repita la animación del ejemplo.\n",
        "\n",
        "- Repita para un mapeo por Gaussianas (RBF) de orden 30.\n",
        "\n"
      ],
      "metadata": {
        "id": "puhW55kvGxf4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W80tfclj2PPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcBsQBSfvluj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}