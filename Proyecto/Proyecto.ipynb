{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivansst773/Aprendizaje_de_Maquina/blob/main/Proyecto/Proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDzjY9zSLqIA",
        "outputId": "744e575a-451d-4692-d800-b30ae5f03e70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=89c62078ad8fb3c2c1249d8293567644f2c48a8ec615a5bed4755f522959f6c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conectar tu Google Drive:\n"
      ],
      "metadata": {
        "id": "71ioqkqry_gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkbxTlclmZXP",
        "outputId": "780150ea-7c37-4003-fee0-2707f1dd3ac1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "descomprimir todos los archivos dentro del ZIP"
      ],
      "metadata": {
        "id": "2jk_PwFfy5kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile, os, glob\n",
        "\n",
        "# Montar Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ruta_zip = \"/content/drive/MyDrive/Semestre2025_1/Teoria de aprendizaje de maquina/a-comprehensive-dataset-of-pattern-electroretinograms-for-ocular-electrophysiology-research-the-perg-ioba-dataset-1.0.0.zip\"\n",
        "ruta_destino = \"/content/perg-ioba-dataset/\"\n",
        "\n",
        "# Extraer ZIP solo si no se ha hecho\n",
        "if not os.path.exists(ruta_destino) or len(os.listdir(ruta_destino)) == 0:\n",
        "    with zipfile.ZipFile(ruta_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(ruta_destino)\n",
        "\n",
        "# Detectar subcarpeta con los datos\n",
        "subcarpetas = [os.path.join(ruta_destino, f) for f in os.listdir(ruta_destino) if os.path.isdir(os.path.join(ruta_destino, f))]\n",
        "ruta_base = subcarpetas[0]  # Asume que hay una sola subcarpeta principal\n",
        "\n",
        "# Buscar CSVs\n",
        "csv_files = glob.glob(os.path.join(ruta_base, \"*.csv\"))\n",
        "print(f\"Se encontraron {len(csv_files)} archivos CSV en {ruta_base}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE5kCxYZvWIM",
        "outputId": "a08ef102-84fc-4a53-f15b-76a6d363ba03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos extra√≠dos en: /content/perg-ioba-dataset/\n",
            "['a-comprehensive-dataset-of-pattern-electroretinograms-for-ocular-electrophysiology-research-the-perg-ioba-dataset-1.0.0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "procesa archivos CSV de mediciones PERG y les asigna un identificador (id_record) basado en el nombre del archivo.\n",
        "\n",
        "üìå Resultado:\n",
        "\n",
        "‚úÖ Cada archivo CSV se convierte en un DataFrame con su informaci√≥n de medici√≥n y su identificador √∫nico (id_record).\n",
        "\n",
        "‚úÖ Permite unir todos los datos en df_mediciones para su an√°lisis posterior.\n"
      ],
      "metadata": {
        "id": "QUbogvi6vIpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# ‚úÖ Ruta corregida\n",
        "ruta_base = \"/content/perg-ioba-dataset/a-comprehensive-dataset-of-pattern-electroretinograms-for-ocular-electrophysiology-research-the-perg-ioba-dataset-1.0.0/\"\n",
        "\n",
        "# Buscar archivos CSV ahora en la ruta correcta\n",
        "csv_files = glob.glob(ruta_base + \"*.csv\")\n",
        "print(f\"Se encontraron {len(csv_files)} archivos CSV\")\n"
      ],
      "metadata": {
        "id": "x5dYZny8HQP4",
        "outputId": "3ec85c8f-b8ba-41ea-8242-c31232b2116d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron 0 archivos CSV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = []\n",
        "for file in csv_files:\n",
        "    if \"participants_info\" in file:  # Excluir el archivo de informaci√≥n de participantes\n",
        "        continue\n",
        "\n",
        "    id_record = os.path.basename(file).split(\".\")[0]  # Extraer ID desde el nombre del archivo\n",
        "    df = pd.read_csv(file)\n",
        "    df[\"id_record\"] = int(id_record)  # Asignar ID al dataset\n",
        "    dataframes.append(df)"
      ],
      "metadata": {
        "id": "izIeJnjklMBd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo fusiona todos los DataFrames en un √∫nico dataset (df_mediciones) y verifica la asignaci√≥n de id_record y valores faltantes (NaN).\n"
      ],
      "metadata": {
        "id": "lC0vwTax1AKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unir todos los DataFrames en un solo dataset\n",
        "df_mediciones = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Revisar si id_record est√° correctamente asignado\n",
        "print(\"Primeras filas despu√©s de asignar id_record:\")\n",
        "print(df_mediciones.head())\n",
        "\n",
        "print(\"\\nConteo de valores NaN en df_mediciones:\")\n",
        "print(df_mediciones.isna().sum())"
      ],
      "metadata": {
        "id": "gHEaFHNsmJBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìç Pr√≥ximo paso: Fusionar df_mediciones con df_info utilizando id_record\n",
        "Ejecuta esto para unir los datos de medici√≥n con la informaci√≥n cl√≠nica:\n"
      ],
      "metadata": {
        "id": "d72G_J3DmkNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo = df_mediciones.merge(df_info, on=\"id_record\", how=\"left\")\n",
        "\n",
        "print(\"Datos combinados correctamente:\")\n",
        "print(df_completo.head())\n",
        "\n",
        "print(\"\\nConteo de valores NaN en df_completo:\")\n",
        "print(df_completo.isna().sum())"
      ],
      "metadata": {
        "id": "jvigwJh3mffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cuenta cu√°ntos pacientes tienen todas sus mediciones PERG como NaN, lo que significa que no tienen datos de respuesta electrofisiol√≥gica registrados.\n"
      ],
      "metadata": {
        "id": "aG8bFngK1SqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N√∫mero de pacientes con todas las mediciones PERG como NaN:\",\n",
        "      df_completo[df_completo[[\"RE_1\", \"LE_1\", \"RE_2\", \"LE_2\", \"RE_3\", \"LE_3\", \"RE_4\", \"LE_4\", \"RE_5\", \"LE_5\"]].isna().all(axis=1)].shape[0])"
      ],
      "metadata": {
        "id": "temTXIm5nEjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisar diagnosis2 y diagnosis3\n",
        "Primero, ejecuta esto para ver cu√°les son los valores m√°s comunes en estas columnas:\n"
      ],
      "metadata": {
        "id": "8X5naTPvoBoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valores √∫nicos en diagnosis2:\")\n",
        "print(df_completo[\"diagnosis2\"].value_counts())\n",
        "\n",
        "print(\"\\nValores √∫nicos en diagnosis3:\")\n",
        "print(df_completo[\"diagnosis3\"].value_counts())"
      ],
      "metadata": {
        "id": "SIeFo13Hn8ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si prefieres rellenar con \"Desconocido\"\n"
      ],
      "metadata": {
        "id": "4aORVCt7rLAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo limpia los valores faltantes (NaN) en las columnas diagnosis2 y diagnosis3, reemplaz√°ndolos por \"Desconocido\".\n"
      ],
      "metadata": {
        "id": "kmL-9YI61jWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo = df_completo.copy()  # Asegurar que estamos modificando el DataFrame original\n",
        "\n",
        "df_completo[\"diagnosis2\"] = df_completo[\"diagnosis2\"].fillna(\"Desconocido\")\n",
        "df_completo[\"diagnosis3\"] = df_completo[\"diagnosis3\"].fillna(\"Desconocido\")"
      ],
      "metadata": {
        "id": "jLpRSapfrCXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo cuenta cu√°ntos registros tienen valores NaN en las columnas unilateral, rep_record y comments.\n"
      ],
      "metadata": {
        "id": "g_l-PpBx1qS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N√∫mero de registros con NaN en unilateral:\", df_completo[\"unilateral\"].isna().sum())\n",
        "print(\"N√∫mero de registros con NaN en rep_record:\", df_completo[\"rep_record\"].isna().sum())\n",
        "print(\"N√∫mero de registros con NaN en comments:\", df_completo[\"comments\"].isna().sum())"
      ],
      "metadata": {
        "id": "2fEjGdlprefW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo elimina valores NaN en las columnas unilateral, rep_record y comments, reemplaz√°ndolos con \"Desconocido\".\n"
      ],
      "metadata": {
        "id": "A4ra5NZo1z8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo = df_completo.copy()  # Asegurar que estamos modificando el DataFrame original\n",
        "\n",
        "df_completo[\"unilateral\"] = df_completo[\"unilateral\"].fillna(\"Desconocido\")\n",
        "df_completo[\"rep_record\"] = df_completo[\"rep_record\"].fillna(\"Desconocido\")\n",
        "df_completo[\"comments\"] = df_completo[\"comments\"].fillna(\"Desconocido\")"
      ],
      "metadata": {
        "id": "1F1fb2rtrng3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo proporciona un resumen detallado del dataset df_completo y estad√≠sticas de las mediciones PERG.\n"
      ],
      "metadata": {
        "id": "8pOWnnZb2B6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resumen del dataset:\")\n",
        "print(df_completo.info())\n",
        "\n",
        "print(\"\\nEstad√≠sticas de las mediciones:\")\n",
        "print(df_completo.describe())"
      ],
      "metadata": {
        "id": "Q-bPHrQ9sKFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Vamos a construir un modelo de clasificaci√≥n para predecir diagnosis1 con base en las mediciones PERG y los datos cl√≠nicos\n"
      ],
      "metadata": {
        "id": "Nz_KMV6VtgWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ üìç ¬øQu√© es un modelo de clasificaci√≥n en Machine Learning?\n",
        "\n",
        "‚úÖ Un modelo de clasificaci√≥n es un algoritmo que aprende a asignar etiquetas a datos nuevos, bas√°ndose en patrones encontrados en datos previos.\n",
        "\n",
        "‚úÖ En nuestro caso, el modelo analizar√° las mediciones PERG (RE_1, LE_1, RE_2, etc.) junto con variables cl√≠nicas (age_years, va_re_logMar, etc.) para predecir el diagn√≥stico (diagnosis1).\n",
        "\n",
        "‚úÖ La meta es que, dado un nuevo paciente con sus mediciones, el modelo pueda decir qu√© diagn√≥stico es m√°s probable.\n"
      ],
      "metadata": {
        "id": "tvf1Zx-IuCF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ La meta es que, dado un nuevo paciente con sus mediciones, el modelo pueda decir qu√© diagn√≥stico es m√°s probable."
      ],
      "metadata": {
        "id": "M3vwlQNzyD0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ üìç Tipos de modelos de clasificaci√≥n\n",
        "Existen muchos algoritmos de clasificaci√≥n, pero aqu√≠ hay algunos populares:\n",
        "\n",
        "üìå Random Forest ‚Üí Usa m√∫ltiples √°rboles de decisi√≥n para mejorar la precisi√≥n.\n",
        "\n",
        "üìå Red Neuronal Artificial (MLP) ‚Üí Aprende patrones en datos complejos, similar a c√≥mo lo hace el cerebro humano.\n",
        "\n",
        "üìå Regresi√≥n Log√≠stica ‚Üí Modelo estad√≠stico simple pero efectivo para problemas binarios o multinivel.\n",
        "\n",
        "üìå K-Nearest Neighbors (KNN) ‚Üí Predice en funci√≥n de los datos m√°s cercanos en el espacio de caracter√≠sticas.\n",
        "\n",
        "üìå Support Vector Machines (SVM) ‚Üí Encuentra la mejor separaci√≥n entre clases con hiperplanos en dimensiones m√∫ltiples.\n"
      ],
      "metadata": {
        "id": "mTtJXlEtuO09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ üìç ¬øC√≥mo funciona el aprendizaje en un modelo de clasificaci√≥n?\n",
        "\n",
        "üîπ Fase de entrenamiento:\n",
        "\n",
        "‚úÖ Se le dan datos etiquetados al modelo (X_train con mediciones + y_train con diagnosis1).\n",
        "\n",
        "‚úÖ El modelo encuentra patrones en los datos y ajusta sus par√°metros internos.\n",
        "\n",
        "üîπ Fase de predicci√≥n:\n",
        "\n",
        "‚úÖ Con nuevos datos (X_test), el modelo usa lo aprendido para asignar un diagn√≥stico (y_pred).\n",
        "\n",
        "‚úÖ Se compara con los valores reales (y_test) y se mide la precisi√≥n del modelo.\n",
        "\n",
        "üîπ Evaluaci√≥n del modelo:\n",
        "\n",
        "‚úÖ Se usan m√©tricas como accuracy, precision, recall y F1-score para medir su desempe√±o.\n",
        "\n",
        "‚úÖ Tambi√©n podemos usar una matriz de confusi√≥n para ver cu√°ntas predicciones fueron correctas o incorrectas.\n"
      ],
      "metadata": {
        "id": "G1LWrdeSujlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ üìç ¬øCu√°l usamos en este proyecto?\n",
        "\n",
        "üìå Random Forest es una gran opci√≥n inicial porque es preciso, f√°cil de interpretar y funciona bien con datos tabulares.\n"
      ],
      "metadata": {
        "id": "SDk3qmmHu0-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ üìç C√≥digo para preparar los datos\n"
      ],
      "metadata": {
        "id": "NNVHqnv2tonn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Selecci√≥n de caracter√≠sticas y etiquetas\n",
        "features = [\"RE_1\", \"LE_1\", \"RE_2\", \"LE_2\", \"age_years\", \"va_re_logMar\", \"va_le_logMar\"]\n",
        "X = df_completo[features]  # Variables predictoras\n",
        "y = df_completo[\"diagnosis1\"]  # Etiqueta de clasificaci√≥n\n",
        "\n",
        "# Codificaci√≥n de etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Divisi√≥n en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizaci√≥n de las caracter√≠sticas\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Datos listos para el entrenamiento del modelo de clasificaci√≥n!\")\n",
        "print(\"Shape de X_train:\", X_train_scaled.shape)\n",
        "print(\"Shape de X_test:\", X_test_scaled.shape)\n"
      ],
      "metadata": {
        "id": "bCwhGWAPtiSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZvKGlpeusJj-"
      }
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=df)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "TaETCegs-CZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. ü§ñ Ense√±ar al modelo (Random Forest)"
      ],
      "metadata": {
        "id": "flP-QBWoErkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo_rf = RandomForestClassifier(random_state=42)\n",
        "modelo_rf.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "zN_KHzvEErTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. üß† Ver c√≥mo responde el robot"
      ],
      "metadata": {
        "id": "GeKkuVb7EyQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = modelo_rf.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "yXMuSwB3E0nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. üìä Evaluar qu√© tan bien lo hizo"
      ],
      "metadata": {
        "id": "YHwmhON_E4C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "matriz = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(matriz, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matriz de confusi√≥n')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Real')\n",
        "plt.savefig('matriz_confusion.pdf')  # Para llevar a Overleaf\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rZ_WwL6DE5r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. üåü Ver qu√© variables us√≥ m√°s el robot para decidir"
      ],
      "metadata": {
        "id": "dBaRH3zbE_P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "importancias = modelo_rf.feature_importances_\n",
        "features = [\"RE_1\", \"LE_1\", \"RE_2\", \"LE_2\", \"age_years\", \"va_re_logMar\", \"va_le_logMar\"]\n",
        "df_importancias = pd.DataFrame({'Feature': features, 'Importancia': importancias})\n",
        "print(df_importancias.sort_values(by='Importancia', ascending=False))\n"
      ],
      "metadata": {
        "id": "Uul7rfR0FDAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d7M-DphwFBsN"
      }
    }
  ]
}