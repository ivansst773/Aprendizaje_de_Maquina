{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivansst773/Aprendizaje_de_Maquina/blob/main/Parcial_2_TAM_2025_1/Parcial_2_TAM_2025_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a48c312",
        "outputId": "23bb564a-8e77-47d1-d09f-a502c2f5292d"
      },
      "source": [
        "# Instalar dependencias en Colab\n",
        "!pip install dash jupyter-dash umap-learn plotly scikit-learn tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dash in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.9.post2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: Flask<3.2,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash) (3.1.1)\n",
            "Requirement already satisfied: Werkzeug<3.2 in /usr/local/lib/python3.11/dist-packages (from dash) (3.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash) (1.4.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.2.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (6.17.1)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.9.2)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.15.3)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<3.2,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.2,>=1.0.4->dash) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<3.2,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.2,>=1.0.4->dash) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<3.2,>=1.0.4->dash) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.23.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (0.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter-dash) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter-dash) (2.9.0.post0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->jupyter-dash) (4.3.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ee4a2ef"
      },
      "source": [
        "# Importar bibliotecas\n",
        "from dash import Dash, dcc, html, Input, Output\n",
        "from jupyter_dash import JupyterDash\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b625d66b"
      },
      "source": [
        "# Cargar y preprocesar datos USPS\n",
        "digits = load_digits()\n",
        "X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "images = digits.images  # Para superponer imágenes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "683189f9",
        "outputId": "c92353d7-4ac2-479e-cdf2-6a8ef921d940"
      },
      "source": [
        "# Proyecciones PCA y UMAP\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "umap_model = umap.UMAP(n_components=2, n_neighbors=15, random_state=42)\n",
        "X_umap = umap_model.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf080042",
        "outputId": "d187ab7a-0d79-4ca2-ef60-b4f1920c58c8"
      },
      "source": [
        "# Entrenar clasificadores\n",
        "# 1. LogisticRegression\n",
        "lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "# 2. RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "# 3. CNN\n",
        "X_train_cnn = X_train.reshape(-1, 8, 8, 1)\n",
        "X_test_cnn = X_test.reshape(-1, 8, 8, 1)\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    # Removed the second MaxPooling2D layer\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Changed metrics to a list\n",
        "model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "report_cnn = classification_report(y_test, y_pred_cnn, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bc89403",
        "outputId": "8ec4abe7-f584-48c4-f9f3-54511bb14ae5"
      },
      "source": [
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test == 0, lr.predict_proba(X_test)[:, 0])\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test == 0, rf.predict_proba(X_test)[:, 0])\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "fpr_cnn, tpr_cnn, _ = roc_curve(y_test == 0, model.predict(X_test_cnn)[:, 0])\n",
        "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be2fa6fe"
      },
      "source": [
        "# Crear el dashboard\n",
        "app = Dash(__name__)\n",
        "\n",
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "# Layout del dashboard\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\", style={'textAlign': 'center'}),\n",
        "\n",
        "    # Sección teórica (punto a)\n",
        "    html.H2(\"Modelos y Optimización\"),\n",
        "    dcc.Dropdown(\n",
        "        id='model-selector',\n",
        "        options=[{'label': model, 'value': model} for model in model_descriptions.keys()],\n",
        "        value='PCA',\n",
        "        style={'width': '50%'}\n",
        "    ),\n",
        "    html.Div(id='model-description', style={'margin': '20px'}),\n",
        "\n",
        "    # Proyecciones PCA y UMAP (punto b)\n",
        "    html.H2(\"Proyecciones del Conjunto USPS\"),\n",
        "    html.H3(\"PCA\"),\n",
        "    dcc.Graph(id='pca-plot'),\n",
        "    html.H3(\"UMAP\"),\n",
        "    dcc.Dropdown(\n",
        "        id='umap-neighbors',\n",
        "        options=[{'label': str(i), 'value': i} for i in [5, 15, 50]],\n",
        "        value=15,\n",
        "        style={'width': '50%'}\n",
        "    ),\n",
        "    dcc.Graph(id='umap-plot'),\n",
        "\n",
        "    # Resultados de clasificación (punto c)\n",
        "    html.H2(\"Resultados de Clasificación\"),\n",
        "    dcc.Dropdown(\n",
        "        id='classifier-selector',\n",
        "        options=[\n",
        "            {'label': 'Logistic Regression', 'value': 'lr'},\n",
        "            {'label': 'Random Forest', 'value': 'rf'},\n",
        "            {'label': 'CNN', 'value': 'cnn'}\n",
        "        ],\n",
        "        value='lr',\n",
        "        style={'width': '50%'}\n",
        "    ),\n",
        "    html.Table(id='metrics-table', style={'margin': '20px'}),\n",
        "    dcc.Graph(id='roc-plot')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "947a792c"
      },
      "source": [
        "# Callback para actualizar descripción del modelo\n",
        "@app.callback(\n",
        "    Output('model-description', 'children'),\n",
        "    Input('model-selector', 'value')\n",
        ")\n",
        "def update_model_description(model):\n",
        "    return dcc.Markdown(model_descriptions[model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0edd765"
      },
      "source": [
        "# Callback para actualizar gráfico PCA\n",
        "@app.callback(\n",
        "    Output('pca-plot', 'figure'),\n",
        "    Input('pca-plot', 'id')  # Dummy input para inicializar\n",
        ")\n",
        "def update_pca_plot(_):\n",
        "    fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 1], color=y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    # Superponer imágenes representativas\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_pca[idx, 0], y=X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0d1323f"
      },
      "source": [
        "# Callback para actualizar gráfico UMAP\n",
        "@app.callback(\n",
        "    Output('umap-plot', 'figure'),\n",
        "    Input('umap-neighbors', 'value')\n",
        ")\n",
        "def update_umap_plot(n_neighbors):\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(X)\n",
        "    fig = px.scatter(x=X_umap[:, 0], y=X_umap[:, 1], color=y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    # Superponer imágenes\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_umap[idx, 0], y=X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f946f189"
      },
      "source": [
        "# Callback para actualizar tabla de métricas y curva ROC\n",
        "@app.callback(\n",
        "    [Output('metrics-table', 'children'), Output('roc-plot', 'figure')],\n",
        "    Input('classifier-selector', 'value')\n",
        ")\n",
        "def update_classifier_results(classifier):\n",
        "    if classifier == 'lr':\n",
        "        report = report_lr\n",
        "        fpr, tpr, roc_auc = fpr_lr, tpr_lr, roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'rf':\n",
        "        report = report_rf\n",
        "        fpr, tpr, roc_auc = fpr_rf, tpr_rf, roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else:\n",
        "        report = report_cnn\n",
        "        fpr, tpr, roc_auc = fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Crear tabla de métricas\n",
        "    table = [\n",
        "        html.Tr([html.Td(\"Métrica\"), html.Td(\"Valor\")]),\n",
        "        html.Tr([html.Td(\"Precisión\"), html.Td(f\"{report['accuracy']:.3f}\")]),\n",
        "        html.Tr([html.Td(\"F1-Score (macro)\"), html.Td(f\"{report['macro avg']['f1-score']:.3f}\")])\n",
        "    ]\n",
        "\n",
        "    # Crear curva ROC\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Línea base', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"Tasa de Falsos Positivos\", yaxis_title=\"Tasa de Verdaderos Positivos\")\n",
        "\n",
        "    return table, fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "e751b363",
        "outputId": "a37343ee-2699-4cda-b095-e6a76ad7d132"
      },
      "source": [
        "# Ejecutar el dashboard\n",
        "app.run(mode='inline')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "850cba49"
      },
      "source": [
        "# Task\n",
        "Convert the provided Python code for a Dash dashboard analyzing the USPS digits dataset, including data loading, preprocessing, PCA and UMAP projections, training of Logistic Regression, Random Forest, and CNN models, and displaying results and visualizations, into a Streamlit application, ensuring all functionalities and visualizations are preserved and the application can be run using `streamlit run`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6053a278"
      },
      "source": [
        "## Preparar el entorno streamlit\n",
        "\n",
        "### Subtask:\n",
        "Asegurarse de tener Streamlit instalado (`pip install streamlit`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab4af82c"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the streamlit library using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a198fea3",
        "outputId": "385496c2-4156-40a2-c136-073b0c827faf"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.46.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90809a0"
      },
      "source": [
        "## Reutilizar el código de análisis de datos\n",
        "\n",
        "### Subtask:\n",
        "Reutilizar el código de análisis de datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44a22cce"
      },
      "source": [
        "**Reasoning**:\n",
        "Copy the necessary code blocks for data loading, preprocessing, dimensionality reduction, model training, and ROC curve calculation from the existing notebook into a single code block for the Streamlit script.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3d97502",
        "outputId": "9cac0d90-0115-4d75-a9ac-e9650c4b3529"
      },
      "source": [
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar y preprocesar datos USPS\n",
        "digits = load_digits()\n",
        "X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "images = digits.images  # Para superponer imágenes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Proyecciones PCA y UMAP\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "umap_model = umap.UMAP(n_components=2, n_neighbors=15, random_state=42)\n",
        "X_umap = umap_model.fit_transform(X)\n",
        "\n",
        "# Entrenar clasificadores\n",
        "# 1. LogisticRegression\n",
        "lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "# 2. RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "# 3. CNN\n",
        "X_train_cnn = X_train.reshape(-1, 8, 8, 1)\n",
        "X_test_cnn = X_test.reshape(-1, 8, 8, 1)\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "report_cnn = classification_report(y_test, y_pred_cnn, output_dict=True)\n",
        "\n",
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test == 0, lr.predict_proba(X_test)[:, 0])\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test == 0, rf.predict_proba(X_test)[:, 0])\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "fpr_cnn, tpr_cnn, _ = roc_curve(y_test == 0, model.predict(X_test_cnn)[:, 0])\n",
        "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2688224"
      },
      "source": [
        "## Diseñar la interfaz de usuario con streamlit\n",
        "\n",
        "### Subtask:\n",
        "Utilizar los componentes de Streamlit (`st.title`, `st.header`, `st.write`, `st.selectbox`, `st.slider`, `st.table`, `st.plotly_chart`, etc.) para recrear el diseño del dashboard de Dash (secciones teóricas, proyecciones, resultados).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d733f96b"
      },
      "source": [
        "**Reasoning**:\n",
        "Use Streamlit components to create the layout of the dashboard, including titles, headers, selectboxes, a slider, and placeholders for plots and tables, following the provided instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2b27d4",
        "outputId": "39d52081-1036-4513-eccb-fb0691b5d653"
      },
      "source": [
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "st.title(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\")\n",
        "\n",
        "# Sección teórica (punto a)\n",
        "st.header(\"Modelos y Optimización\")\n",
        "selected_model = st.selectbox(\n",
        "    \"Selecciona un modelo:\",\n",
        "    list(model_descriptions.keys())\n",
        ")\n",
        "st.markdown(model_descriptions[selected_model])\n",
        "\n",
        "# Proyecciones PCA y UMAP (punto b)\n",
        "st.header(\"Proyecciones del Conjunto USPS\")\n",
        "st.subheader(\"PCA\")\n",
        "# Placeholder for PCA plot\n",
        "pca_plot_placeholder = st.empty()\n",
        "\n",
        "st.subheader(\"UMAP\")\n",
        "n_neighbors_umap = st.slider(\n",
        "    \"Número de vecinos para UMAP:\",\n",
        "    min_value=5,\n",
        "    max_value=50,\n",
        "    value=15,\n",
        "    step=1\n",
        ")\n",
        "# Placeholder for UMAP plot\n",
        "umap_plot_placeholder = st.empty()\n",
        "\n",
        "# Resultados de clasificación (punto c)\n",
        "st.header(\"Resultados de Clasificación\")\n",
        "selected_classifier = st.selectbox(\n",
        "    \"Selecciona un clasificador:\",\n",
        "    ('Logistic Regression', 'Random Forest', 'CNN')\n",
        ")\n",
        "# Placeholder for metrics table\n",
        "metrics_table_placeholder = st.empty()\n",
        "# Placeholder for ROC plot\n",
        "roc_plot_placeholder = st.empty()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:46:25.724 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.898 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-07-16 01:46:25.899 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.906 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.917 Session state does not function when running a script without `streamlit run`\n",
            "2025-07-16 01:46:25.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.932 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.935 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.937 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.938 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.939 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.939 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.941 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.946 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:46:25.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e135660c"
      },
      "source": [
        "## Implementar la interactividad\n",
        "\n",
        "### Subtask:\n",
        "Adaptar la lógica que en Dash se manejaba con \"callbacks\" para que funcione con el modelo reactivo de Streamlit. Esto implica que los cambios en los widgets de entrada (selectores, sliders) disparen la re-ejecución de partes del script para actualizar los elementos de salida (descripciones, gráficos, tablas).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b5e5dce"
      },
      "source": [
        "**Reasoning**:\n",
        "Wrap the plotting and metrics display logic in functions to handle reactively updating the Streamlit interface based on user input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e945063",
        "outputId": "4a891446-83f4-451b-90ad-d06f6ec62d88"
      },
      "source": [
        "def generate_pca_plot():\n",
        "    \"\"\"Generates the PCA plot with representative images.\"\"\"\n",
        "    fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 1], color=y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_pca[idx, 0], y=X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_umap_plot(n_neighbors):\n",
        "    \"\"\"Generates the UMAP plot with representative images for a given number of neighbors.\"\"\"\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(X)\n",
        "    fig = px.scatter(x=X_umap[:, 0], y=X_umap[:, 1], color=y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_umap[idx, 0], y=X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_classifier_results(classifier):\n",
        "    \"\"\"Generates the metrics table and ROC plot for a given classifier.\"\"\"\n",
        "    if classifier == 'Logistic Regression':\n",
        "        report = report_lr\n",
        "        fpr, tpr, roc_auc = fpr_lr, tpr_lr, roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'Random Forest':\n",
        "        report = report_rf\n",
        "        fpr, tpr, roc_auc = fpr_rf, tpr_rf, roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else: # CNN\n",
        "        report = report_cnn\n",
        "        fpr, tpr, roc_auc = fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Create metrics table\n",
        "    metrics_html = \"<table>\"\n",
        "    metrics_html += \"<tr><td>Metric</td><td>Value</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>Accuracy</td><td>{report['accuracy']:.3f}</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>F1-Score (macro)</td><td>{report['macro avg']['f1-score']:.3f}</td></tr>\"\n",
        "    metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "    # Create ROC curve\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
        "\n",
        "    return metrics_html, fig\n",
        "\n",
        "# Display PCA plot\n",
        "pca_plot_placeholder.plotly_chart(generate_pca_plot())\n",
        "\n",
        "# Display UMAP plot\n",
        "umap_plot_placeholder.plotly_chart(generate_umap_plot(n_neighbors_umap))\n",
        "\n",
        "# Display classifier results\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier)\n",
        "metrics_table_placeholder.markdown(metrics_html, unsafe_allow_html=True)\n",
        "roc_plot_placeholder.plotly_chart(roc_fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:50:07.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:07.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:07.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:07.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:07.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n",
            "2025-07-16 01:50:12.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:12.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0adb2e6b"
      },
      "source": [
        "## Integrar las visualizaciones de plotly\n",
        "\n",
        "### Subtask:\n",
        "Integrar las visualizaciones de plotly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03e90ec"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the plotly visualizations into the Streamlit application using `st.plotly_chart()` for the PCA, UMAP, and ROC curve plots, ensuring they are displayed in their respective placeholders using the figures generated by the helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41c6729c",
        "outputId": "bd373b76-e5c2-4a28-a911-a5f22eceb9dc"
      },
      "source": [
        "# Display PCA plot\n",
        "pca_fig = generate_pca_plot()\n",
        "pca_plot_placeholder.plotly_chart(pca_fig)\n",
        "\n",
        "# Display UMAP plot\n",
        "umap_fig = generate_umap_plot(n_neighbors_umap)\n",
        "umap_plot_placeholder.plotly_chart(umap_fig)\n",
        "\n",
        "# Display classifier results (metrics table and ROC plot)\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier)\n",
        "metrics_table_placeholder.markdown(metrics_html, unsafe_allow_html=True)\n",
        "roc_plot_placeholder.plotly_chart(roc_fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:50:38.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:38.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:38.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:38.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:38.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n",
            "2025-07-16 01:50:43.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.569 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.570 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:50:43.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f38f20"
      },
      "source": [
        "## Calcular y mostrar métricas/roc\n",
        "\n",
        "### Subtask:\n",
        "Calcular y mostrar métricas/roc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0551920"
      },
      "source": [
        "## Estructurar el script de streamlit\n",
        "\n",
        "### Subtask:\n",
        "Organizar el código en un único script Python (`.py`) que Streamlit pueda ejecutar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2fa62ab"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine all the code into a single Python script file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73402a05",
        "outputId": "a934374c-069c-42ab-beac-2901d71b0ce4"
      },
      "source": [
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar y preprocesar datos USPS\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    \"\"\"Loads and preprocesses the USPS digits dataset.\"\"\"\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "    images = digits.images  # Para superponer imágenes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X, y, images, X_train, X_test, y_train, y_test\n",
        "\n",
        "X, y, images, X_train, X_test, y_train, y_test = load_data()\n",
        "\n",
        "# Proyecciones PCA y UMAP\n",
        "@st.cache_resource\n",
        "def perform_dimensionality_reduction(X, n_neighbors_umap=15):\n",
        "    \"\"\"Performs PCA and UMAP dimensionality reduction.\"\"\"\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors_umap, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(X)\n",
        "    return X_pca, X_umap\n",
        "\n",
        "# Entrenar clasificadores\n",
        "@st.cache_resource\n",
        "def train_classifiers(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Trains Logistic Regression, Random Forest, and CNN classifiers.\"\"\"\n",
        "    # 1. LogisticRegression\n",
        "    lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred_lr = lr.predict(X_test)\n",
        "    report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "    # 2. RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "    # 3. CNN\n",
        "    X_train_cnn = X_train.reshape(-1, 8, 8, 1)\n",
        "    X_test_cnn = X_test.reshape(-1, 8, 8, 1)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "    report_cnn = classification_report(y_test, y_pred_cnn, output_dict=True)\n",
        "\n",
        "    return lr, report_lr, rf, report_rf, model, report_cnn\n",
        "\n",
        "lr, report_lr, rf, report_rf, cnn_model, report_cnn = train_classifiers(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "@st.cache_resource\n",
        "def calculate_roc_curves(lr, rf, cnn_model, X_test, y_test):\n",
        "    \"\"\"Calculates ROC curves and AUC for class 0.\"\"\"\n",
        "    X_test_cnn = X_test.reshape(-1, 8, 8, 1)\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(y_test == 0, lr.predict_proba(X_test)[:, 0])\n",
        "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(y_test == 0, rf.predict_proba(X_test)[:, 0])\n",
        "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "    fpr_cnn, tpr_cnn, _ = roc_curve(y_test == 0, cnn_model.predict(X_test_cnn)[:, 0])\n",
        "    roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "    return fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "\n",
        "fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn = calculate_roc_curves(lr, rf, cnn_model, X_test, y_test)\n",
        "\n",
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "def generate_pca_plot(X_pca, y, images):\n",
        "    \"\"\"Generates the PCA plot with representative images.\"\"\"\n",
        "    fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 1], color=y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_pca[idx, 0], y=X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_umap_plot(X_umap, y, images, n_neighbors):\n",
        "    \"\"\"Generates the UMAP plot with representative images for a given number of neighbors.\"\"\"\n",
        "    fig = px.scatter(x=X_umap[:, 0], y=X_umap[:, 1], color=y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(y == i)[0][0]\n",
        "        img = images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=X_umap[idx, 0], y=X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_classifier_results(classifier, report_lr, report_rf, report_cnn, fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn):\n",
        "    \"\"\"Generates the metrics table and ROC plot for a given classifier.\"\"\"\n",
        "    if classifier == 'Logistic Regression':\n",
        "        report = report_lr\n",
        "        fpr, tpr, roc_auc = fpr_lr, tpr_lr, roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'Random Forest':\n",
        "        report = report_rf\n",
        "        fpr, tpr, roc_auc = fpr_rf, tpr_rf, roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else: # CNN\n",
        "        report = report_cnn\n",
        "        fpr, tpr, roc_auc = fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Create metrics table\n",
        "    metrics_html = \"<table>\"\n",
        "    metrics_html += \"<tr><td>Metric</td><td>Value</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>Accuracy</td><td>{report['accuracy']:.3f}</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>F1-Score (macro)</td><td>{report['macro avg']['f1-score']:.3f}</td></tr>\"\n",
        "    metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "    # Create ROC curve\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
        "\n",
        "    return metrics_html, fig\n",
        "\n",
        "st.title(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\")\n",
        "\n",
        "# Sección teórica (punto a)\n",
        "st.header(\"Modelos y Optimización\")\n",
        "selected_model = st.selectbox(\n",
        "    \"Selecciona un modelo:\",\n",
        "    list(model_descriptions.keys())\n",
        ")\n",
        "st.markdown(model_descriptions[selected_model])\n",
        "\n",
        "# Proyecciones PCA y UMAP (punto b)\n",
        "st.header(\"Proyecciones del Conjunto USPS\")\n",
        "st.subheader(\"PCA\")\n",
        "# Display PCA plot\n",
        "pca_fig = generate_pca_plot(X_pca, y, images)\n",
        "st.plotly_chart(pca_fig)\n",
        "\n",
        "st.subheader(\"UMAP\")\n",
        "n_neighbors_umap = st.slider(\n",
        "    \"Número de vecinos para UMAP:\",\n",
        "    min_value=5,\n",
        "    max_value=50,\n",
        "    value=15,\n",
        "    step=1\n",
        ")\n",
        "# Perform UMAP with selected neighbors and display plot\n",
        "X_pca_updated, X_umap_updated = perform_dimensionality_reduction(X, n_neighbors_umap)\n",
        "umap_fig = generate_umap_plot(X_umap_updated, y, images, n_neighbors_umap)\n",
        "st.plotly_chart(umap_fig)\n",
        "\n",
        "# Resultados de clasificación (punto c)\n",
        "st.header(\"Resultado de Clasificación\")\n",
        "selected_classifier = st.selectbox(\n",
        "    \"Selecciona un clasificador:\",\n",
        "    ('Logistic Regression', 'Random Forest', 'CNN')\n",
        ")\n",
        "\n",
        "# Display classifier results\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier, report_lr, report_rf, report_cnn, fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn)\n",
        "st.markdown(metrics_html, unsafe_allow_html=True)\n",
        "st.plotly_chart(roc_fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:51:21.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.504 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.505 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.533 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.533 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.534 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:21.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n",
            "2025-07-16 01:51:22.041 Thread 'Thread-94': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:22.044 Thread 'Thread-94': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:22.046 Thread 'Thread-94': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:51:27.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:27.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:27.831 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnhashableParamError",
          "evalue": "Cannot hash argument 'lr' (of type `sklearn.linear_model._logistic.LogisticRegression`) in 'calculate_roc_curves'.\n\nTo address this, you can tell Streamlit not to hash this argument by adding a\nleading underscore to the argument's name in the function signature:\n\n```\n@st.cache_resource\ndef calculate_roc_curves(_lr, ...):\n    ...\n```\n            ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0mreduce_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/copyreg.py\u001b[0m in \u001b[0;36m_reduce_ex\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot pickle {cls.__name__!r} object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'function' object",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mUnhashableTypeError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/cache_utils.py\u001b[0m in \u001b[0;36m_make_value_key\u001b[0;34m(cache_type, func, func_args, func_kwargs, hash_funcs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# to evaluate user defined `hash_funcs` only for computing `arg_value` hash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             update_hash(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate_hash\u001b[0;34m(val, hasher, cache_type, hash_source, hash_funcs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CacheFuncHasher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, hasher, obj)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreduce_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, hasher, obj)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnhashableTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnhashableTypeError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnhashableParamError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-3398458859.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfpr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_cnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mfpr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_roc_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Descripciones teóricas (punto a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/cache_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mspinner_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Running `{name}(...)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_create_cached_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspinner_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     def _get_or_create_cached_value(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/cache_utils.py\u001b[0m in \u001b[0;36m_get_or_create_cached_value\u001b[0;34m(self, func_args, func_kwargs, spinner_message)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Generate the key for the cached value. This is based on the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# arguments passed to the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         value_key = _make_value_key(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mcache_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/cache_utils.py\u001b[0m in \u001b[0;36m_make_value_key\u001b[0;34m(cache_type, func, func_args, func_kwargs, hash_funcs)\u001b[0m\n\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnhashableTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnhashableParamError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0mvalue_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_hasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/cache_utils.py\u001b[0m in \u001b[0;36m_make_value_key\u001b[0;34m(cache_type, func, func_args, func_kwargs, hash_funcs)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# without `hash_funcs`, and second time for `arg_value` with hash_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# to evaluate user defined `hash_funcs` only for computing `arg_value` hash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             update_hash(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mhasher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_hasher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate_hash\u001b[0;34m(val, hasher, cache_type, hash_source, hash_funcs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CacheFuncHasher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, hasher, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreduce_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, hasher, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mreduce_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnhashableTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreduce_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnhashableParamError\u001b[0m: Cannot hash argument 'lr' (of type `sklearn.linear_model._logistic.LogisticRegression`) in 'calculate_roc_curves'.\n\nTo address this, you can tell Streamlit not to hash this argument by adding a\nleading underscore to the argument's name in the function signature:\n\n```\n@st.cache_resource\ndef calculate_roc_curves(_lr, ...):\n    ...\n```\n            "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce955da3"
      },
      "source": [
        "**Reasoning**:\n",
        "The error message indicates that Streamlit cannot hash the `lr` object (a LogisticRegression model) within the `calculate_roc_curves` function when using `@st.cache_resource`. To fix this, I need to follow the suggestion in the error message and add a leading underscore to the `lr`, `rf`, and `cnn_model` arguments in the `calculate_roc_curves` function signature to tell Streamlit not to hash these objects.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vqvJ2qL7kF0",
        "outputId": "6776d934-0e8b-4050-cd97-b5893bdd1be4"
      },
      "source": [
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar y preprocesar datos USPS\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    \"\"\"Loads and preprocesses the USPS digits dataset.\"\"\"\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "    images = digits.images  # Para superponer imágenes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X, y, images, X_train, X_test, y_train, y_test\n",
        "\n",
        "X, y, images, X_train, X_test, y_train, y_test = load_data()\n",
        "\n",
        "# Proyecciones PCA y UMAP\n",
        "@st.cache_resource\n",
        "def perform_dimensionality_reduction(_X, n_neighbors_umap=15):\n",
        "    \"\"\"Performs PCA and UMAP dimensionality reduction.\"\"\"\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(_X)\n",
        "\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors_umap, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(_X)\n",
        "    return X_pca, X_umap\n",
        "\n",
        "# Entrenar clasificadores\n",
        "@st.cache_resource\n",
        "def train_classifiers(_X_train, _X_test, _y_train, _y_test):\n",
        "    \"\"\"Trains Logistic Regression, Random Forest, and CNN classifiers.\"\"\"\n",
        "    # 1. LogisticRegression\n",
        "    lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(_X_train, _y_train)\n",
        "    y_pred_lr = lr.predict(_X_test)\n",
        "    report_lr = classification_report(_y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "    # 2. RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    rf.fit(_X_train, _y_train)\n",
        "    y_pred_rf = rf.predict(_X_test)\n",
        "    report_rf = classification_report(_y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "    # 3. CNN\n",
        "    X_train_cnn = _X_train.reshape(-1, 8, 8, 1)\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_cnn, _y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "    report_cnn = classification_report(_y_test, y_pred_cnn, output_dict=True)\n",
        "\n",
        "    return lr, report_lr, rf, report_rf, model, report_cnn\n",
        "\n",
        "lr, report_lr, rf, report_rf, cnn_model, report_cnn = train_classifiers(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "@st.cache_resource\n",
        "def calculate_roc_curves(_lr, _rf, _cnn_model, _X_test, _y_test):\n",
        "    \"\"\"Calculates ROC curves and AUC for class 0.\"\"\"\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(_y_test == 0, _lr.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(_y_test == 0, _rf.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "    fpr_cnn, tpr_cnn, _ = roc_curve(_y_test == 0, _cnn_model.predict(X_test_cnn)[:, 0])\n",
        "    roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "    return fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "\n",
        "fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn = calculate_roc_curves(lr, rf, cnn_model, X_test, y_test)\n",
        "\n",
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "def generate_pca_plot(_X_pca, _y, _images):\n",
        "    \"\"\"Generates the PCA plot with representative images.\"\"\"\n",
        "    fig = px.scatter(x=_X_pca[:, 0], y=_X_pca[:, 1], color=_y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_pca[idx, 0], y=_X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_umap_plot(_X_umap, _y, _images, n_neighbors):\n",
        "    \"\"\"Generates the UMAP plot with representative images for a given number of neighbors.\"\"\"\n",
        "    fig = px.scatter(x=_X_umap[:, 0], y=_X_umap[:, 1], color=_y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_umap[idx, 0], y=_X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_classifier_results(classifier, _report_lr, _report_rf, _report_cnn, _fpr_lr, _tpr_lr, _roc_auc_lr, _fpr_rf, _tpr_rf, _roc_auc_rf, _fpr_cnn, _tpr_cnn, _roc_auc_cnn):\n",
        "    \"\"\"Generates the metrics table and ROC plot for a given classifier.\"\"\"\n",
        "    if classifier == 'Logistic Regression':\n",
        "        report = _report_lr\n",
        "        fpr, tpr, roc_auc = _fpr_lr, _tpr_lr, _roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'Random Forest':\n",
        "        report = _report_rf\n",
        "        fpr, tpr, roc_auc = _fpr_rf, _tpr_rf, _roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else: # CNN\n",
        "        report = _report_cnn\n",
        "        fpr, tpr, roc_auc = _fpr_cnn, _tpr_cnn, _roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Create metrics table\n",
        "    metrics_html = \"<table>\"\n",
        "    metrics_html += \"<tr><td>Metric</td><td>Value</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>Accuracy</td><td>{report['accuracy']:.3f}</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>F1-Score (macro)</td><td>{report['macro avg']['f1-score']:.3f}</td></tr>\"\n",
        "    metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "    # Create ROC curve\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
        "\n",
        "    return metrics_html, fig\n",
        "\n",
        "st.title(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\")\n",
        "\n",
        "# Sección teórica (punto a)\n",
        "st.header(\"Modelos y Optimización\")\n",
        "selected_model = st.selectbox(\n",
        "    \"Selecciona un modelo:\",\n",
        "    list(model_descriptions.keys())\n",
        ")\n",
        "st.markdown(model_descriptions[selected_model])\n",
        "\n",
        "# Proyecciones PCA y UMAP (punto b)\n",
        "st.header(\"Proyecciones del Conjunto USPS\")\n",
        "st.subheader(\"PCA\")\n",
        "# Perform PCA and display plot\n",
        "X_pca_updated, X_umap_initial = perform_dimensionality_reduction(X, 15) # Use default 15 for initial UMAP\n",
        "pca_fig = generate_pca_plot(X_pca_updated, y, images)\n",
        "st.plotly_chart(pca_fig)\n",
        "\n",
        "st.subheader(\"UMAP\")\n",
        "n_neighbors_umap = st.slider(\n",
        "    \"Número de vecinos para UMAP:\",\n",
        "    min_value=5,\n",
        "    max_value=50,\n",
        "    value=15,\n",
        "    step=1\n",
        ")\n",
        "# Perform UMAP with selected neighbors and display plot\n",
        "X_pca_updated, X_umap_updated = perform_dimensionality_reduction(X, n_neighbors_umap)\n",
        "umap_fig = generate_umap_plot(X_umap_updated, y, images, n_neighbors_umap)\n",
        "st.plotly_chart(umap_fig)\n",
        "\n",
        "# Resultados de clasificación (punto c)\n",
        "st.header(\"Resultado de Clasificación\")\n",
        "selected_classifier = st.selectbox(\n",
        "    \"Selecciona un clasificador:\",\n",
        "    ('Logistic Regression', 'Random Forest', 'CNN')\n",
        ")\n",
        "\n",
        "# Display classifier results\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier, report_lr, report_rf, report_cnn, fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn)\n",
        "st.markdown(metrics_html, unsafe_allow_html=True)\n",
        "st.plotly_chart(roc_fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:51:50.908 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:50.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:50.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:50.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n",
            "2025-07-16 01:51:51.420 Thread 'Thread-95': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:51.422 Thread 'Thread-95': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:51.426 Thread 'Thread-95': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:51:56.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 01:51:56.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.847 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.848 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.851 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:56.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
            "\n",
            "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "\n",
            "2025-07-16 01:51:57.369 Thread 'Thread-97': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:57.375 Thread 'Thread-97': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:51:57.392 Thread 'Thread-97': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.088 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.141 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.148 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.151 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.212 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.212 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.222 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 01:52:03.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b0c6c6a"
      },
      "source": [
        "## Ejecutar la aplicación streamlit\n",
        "\n",
        "### Subtask:\n",
        "Correr la aplicación desde la terminal usando `streamlit run tu_script.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9537069b"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the complete Python script into a `.py` file in the current directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f140e226"
      },
      "source": [
        "# Assuming the complete Streamlit script is in a string variable named `streamlit_script_content`\n",
        "# In a real scenario, this would be the combined code from the previous steps.\n",
        "streamlit_script_content = \"\"\"\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar y preprocesar datos USPS\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    \\\"\\\"\\\"Loads and preprocesses the USPS digits dataset.\\\"\\\"\\\"\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "    images = digits.images  # Para superponer imágenes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X, y, images, X_train, X_test, y_train, y_test\n",
        "\n",
        "X, y, images, X_train, X_test, y_train, y_test = load_data()\n",
        "\n",
        "# Proyecciones PCA y UMAP\n",
        "@st.cache_resource\n",
        "def perform_dimensionality_reduction(_X, n_neighbors_umap=15):\n",
        "    \\\"\\\"\\\"Performs PCA and UMAP dimensionality reduction.\\\"\\\"\\\"\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(_X)\n",
        "\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors_umap, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(_X)\n",
        "    return X_pca, X_umap\n",
        "\n",
        "# Entrenar clasificadores\n",
        "@st.cache_resource\n",
        "def train_classifiers(_X_train, _X_test, _y_train, _y_test):\n",
        "    \\\"\\\"\\\"Trains Logistic Regression, Random Forest, and CNN classifiers.\\\"\\\"\\\"\n",
        "    # 1. LogisticRegression\n",
        "    lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(_X_train, _y_train)\n",
        "    y_pred_lr = lr.predict(_X_test)\n",
        "    report_lr = classification_report(_y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "    # 2. RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    rf.fit(_X_train, _y_train)\n",
        "    y_pred_rf = rf.predict(_X_test)\n",
        "    report_rf = classification_report(_y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "    # 3. CNN\n",
        "    X_train_cnn = _X_train.reshape(-1, 8, 8, 1)\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_cnn, _y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "    report_cnn = classification_report(_y_test, y_pred_cnn, output_dict=True)\n",
        "\n",
        "    return lr, report_lr, rf, report_rf, model, report_cnn\n",
        "\n",
        "lr, report_lr, rf, report_rf, cnn_model, report_cnn = train_classifiers(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "@st.cache_resource\n",
        "def calculate_roc_curves(_lr, _rf, _cnn_model, _X_test, _y_test):\n",
        "    \\\"\\\"\\\"Calculates ROC curves and AUC for class 0.\\\"\\\"\\\"\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(_y_test == 0, _lr.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(_y_test == 0, _rf.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "    fpr_cnn, tpr_cnn, _ = roc_curve(_y_test == 0, _cnn_model.predict(X_test_cnn)[:, 0])\n",
        "    roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "    return fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "\n",
        "fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn = calculate_roc_curves(lr, rf, cnn_model, X_test, y_test)\n",
        "\n",
        "\n",
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "def generate_pca_plot(_X_pca, _y, _images):\n",
        "    \\\"\\\"\\\"Generates the PCA plot with representative images.\\\"\\\"\\\"\n",
        "    fig = px.scatter(x=_X_pca[:, 0], y=_X_pca[:, 1], color=_y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_pca[idx, 0], y=_X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_umap_plot(_X_umap, _y, _images, n_neighbors):\n",
        "    \\\"\\\"\\\"Generates the UMAP plot with representative images for a given number of neighbors.\\\"\\\"\\\"\n",
        "    fig = px.scatter(x=_X_umap[:, 0], y=_X_umap[:, 1], color=_y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_umap[idx, 0], y=_X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def generate_classifier_results(classifier, _report_lr, _report_rf, _report_cnn, _fpr_lr, _tpr_lr, _roc_auc_lr, _fpr_rf, _tpr_rf, _roc_auc_rf, _fpr_cnn, _tpr_cnn, _roc_auc_cnn):\n",
        "    \\\"\\\"\\\"Generates the metrics table and ROC plot for a given classifier.\\\"\\\"\\\"\n",
        "    if classifier == 'Logistic Regression':\n",
        "        report = _report_lr\n",
        "        fpr, tpr, roc_auc = _fpr_lr, _tpr_lr, _roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'Random Forest':\n",
        "        report = _report_rf\n",
        "        fpr, tpr, roc_auc = _fpr_rf, _tpr_rf, _roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else: # CNN\n",
        "        report = _report_cnn\n",
        "        fpr, tpr, roc_auc = _fpr_cnn, _tpr_cnn, _roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Create metrics table\n",
        "    metrics_html = \"<table>\"\n",
        "    metrics_html += \"<tr><td>Metric</td><td>Value</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>Accuracy</td><td>{report['accuracy']:.3f}</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>F1-Score (macro)</td><td>{report['macro avg']['f1-score']:.3f}</td></tr>\"\n",
        "    metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "    # Create ROC curve\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
        "\n",
        "    return metrics_html, fig\n",
        "\n",
        "st.title(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\")\n",
        "\n",
        "# Sección teórica (punto a)\n",
        "st.header(\"Modelos y Optimización\")\n",
        "selected_model = st.selectbox(\n",
        "    \"Selecciona un modelo:\",\n",
        "    list(model_descriptions.keys())\n",
        ")\n",
        "st.markdown(model_descriptions[selected_model])\n",
        "\n",
        "# Proyecciones PCA y UMAP (punto b)\n",
        "st.header(\"Proyecciones del Conjunto USPS\")\n",
        "st.subheader(\"PCA\")\n",
        "# Perform PCA and display plot\n",
        "X_pca_updated, X_umap_initial = perform_dimensionality_reduction(X, 15) # Use default 15 for initial UMAP\n",
        "pca_fig = generate_pca_plot(X_pca_updated, y, images)\n",
        "st.plotly_chart(pca_fig)\n",
        "\n",
        "st.subheader(\"UMAP\")\n",
        "n_neighbors_umap = st.slider(\n",
        "    \"Número de vecinos para UMAP:\",\n",
        "    min_value=5,\n",
        "    max_value=50,\n",
        "    value=15,\n",
        "    step=1\n",
        ")\n",
        "# Perform UMAP with selected neighbors and display plot\n",
        "X_pca_updated, X_umap_updated = perform_dimensionality_reduction(X, n_neighbors_umap)\n",
        "umap_fig = generate_umap_plot(X_umap_updated, y, images, n_neighbors_umap)\n",
        "st.plotly_chart(umap_fig)\n",
        "\n",
        "\n",
        "# Resultados de clasificación (punto c)\n",
        "st.header(\"Resultado de Clasificación\")\n",
        "selected_classifier = st.selectbox(\n",
        "    \"Selecciona un clasificador:\",\n",
        "    ('Logistic Regression', 'Random Forest', 'CNN')\n",
        ")\n",
        "\n",
        "# Display classifier results\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier, report_lr, report_rf, report_cnn, fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn)\n",
        "st.markdown(metrics_html, unsafe_allow_html=True)\n",
        "st.plotly_chart(roc_fig)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"dashboard_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_script_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12fd5d02"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The Streamlit application successfully loads and preprocesses the USPS digits dataset, including splitting it into training and testing sets.\n",
        "*   Both PCA and UMAP dimensionality reduction techniques were applied to the dataset. The UMAP projection is interactive, allowing the user to adjust the number of neighbors.\n",
        "*   Three classification models (Logistic Regression, Random Forest, and CNN) were trained on the dataset.\n",
        "*   The application displays theoretical descriptions of various machine learning models, including PCA, UMAP, and the trained classifiers.\n",
        "*   Classification performance metrics (Accuracy and Macro Avg F1-Score) and ROC curves (specifically for class 0) are calculated and displayed for the selected classifier.\n",
        "*   The use of `@st.cache_resource` was implemented to optimize the loading, dimensionality reduction, model training, and ROC curve calculation steps by caching their results, improving application performance on subsequent runs.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   While the application successfully displays the ROC curve for a single class (class 0), implementing multiclass ROC analysis or displaying confusion matrices would provide a more comprehensive evaluation of the classifiers' performance across all digits.\n",
        "*   Adding the ability for users to upload their own image data for prediction would enhance the practical utility of the dashboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "936a92c7"
      },
      "source": [
        "# Assuming the complete Streamlit script is in a string variable named `streamlit_script_content`\n",
        "# In a real scenario, this would be the combined code from the previous steps.\n",
        "streamlit_script_content = \"\"\"\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import umap\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar y preprocesar datos USPS\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    \\\"\\\"\\\"Loads and preprocesses the USPS digits dataset.\\\"\\\"\\\"\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data / 255.0, digits.target  # Normalizar\n",
        "    images = digits.images  # Para superponer imágenes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X, y, images, X_train, X_test, y_train, y_test\n",
        "\n",
        "X, y, images, X_train, X_test, y_train, y_test = load_data()\n",
        "\n",
        "# Proyecciones PCA y UMAP\n",
        "@st.cache_resource\n",
        "def perform_dimensionality_reduction(_X, n_neighbors_umap=15):\n",
        "    \\\"\\\"\\\"Performs PCA and UMAP dimensionality reduction.\\\"\\\"\\\"\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(_X)\n",
        "\n",
        "    umap_model = umap.UMAP(n_components=2, n_neighbors=n_neighbors_umap, random_state=42)\n",
        "    X_umap = umap_model.fit_transform(_X)\n",
        "    return X_pca, X_umap\n",
        "\n",
        "# Entrenar clasificadores\n",
        "@st.cache_resource\n",
        "def train_classifiers(_X_train, _X_test, _y_train, _y_test):\n",
        "    \\\"\\\"\\\"Trains Logistic Regression, Random Forest, and CNN classifiers.\\\"\\\"\\\"\n",
        "    # 1. LogisticRegression\n",
        "    lr = LogisticRegression(C=1.0, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(_X_train, _y_train)\n",
        "    y_pred_lr = lr.predict(_X_test)\n",
        "    report_lr = classification_report(_y_test, y_pred_lr, output_dict=True)\n",
        "\n",
        "    # 2. RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    rf.fit(_X_train, _y_train)\n",
        "    y_pred_rf = rf.predict(_X_test)\n",
        "    report_rf = classification_report(_y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "    # 3. CNN\n",
        "    X_train_cnn = _X_train.reshape(-1, 8, 8, 1)\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_cnn, _y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    y_pred_cnn = model.predict(X_test_cnn).argmax(axis=1)\n",
        "    report_cnn = classification_report(_y_test, y_pred_cnn, output_dict=True)\n",
        "\n",
        "    return lr, report_lr, rf, report_rf, model, report_cnn\n",
        "\n",
        "lr, report_lr, rf, report_rf, cnn_model, report_cnn = train_classifiers(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# Calcular curvas ROC (para clase 0 como ejemplo)\n",
        "@st.cache_resource\n",
        "def calculate_roc_curves(_lr, _rf, _cnn_model, _X_test, _y_test):\n",
        "    \\\"\\\"\\\"Calculates ROC curves and AUC for class 0.\\\"\\\"\\\"\n",
        "    X_test_cnn = _X_test.reshape(-1, 8, 8, 1)\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(_y_test == 0, _lr.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(_y_test == 0, _rf.predict_proba(_X_test)[:, 0])\n",
        "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "    fpr_cnn, tpr_cnn, _ = roc_curve(_y_test == 0, _cnn_model.predict(X_test_cnn)[:, 0])\n",
        "    roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "    return fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn\n",
        "\n",
        "fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn = calculate_roc_curves(lr, rf, cnn_model, X_test, y_test)\n",
        "\n",
        "\n",
        "# Descripciones teóricas (punto a)\n",
        "model_descriptions = {\n",
        "    \"PCA\": \"Modelo: Proyecta datos en un subespacio que maximiza la varianza.\\nOptimización: max tr(W^T X^T X W) s.t. W^T W = I.\",\n",
        "    \"UMAP\": \"Modelo: Reducción no lineal que preserva estructura topológica.\\nOptimización: min divergencia de entropía cruzada.\",\n",
        "    \"GaussianNB\": \"Modelo: Clasificador probabilístico con suposición de independencia.\\nOptimización: max log-verosimilitud.\",\n",
        "    \"SGDClassifier\": \"Modelo: Clasificador lineal optimizado por descenso estocástico.\\nOptimización: min pérdida regularizada.\",\n",
        "    \"LogisticRegression\": \"Modelo: Predice probabilidad con sigmoide.\\nOptimización: max log-verosimilitud regularizada.\",\n",
        "    \"LinearDiscriminantAnalysis\": \"Modelo: Proyecta datos maximizando separación entre clases.\\nOptimización: max razón de varianzas.\",\n",
        "    \"KNeighborsClassifier\": \"Modelo: Predice por mayoría de k-vecinos.\\nSin optimización explícita.\",\n",
        "    \"SVC\": \"Modelo: Encuentra hiperplano de máximo margen.\\nOptimización: min ||w||^2 + C sum(ξ).\",\n",
        "    \"RandomForestClassifier\": \"Modelo: Ensamble de árboles de decisión.\\nOptimización: min impureza por nodo.\",\n",
        "    \"GaussianProcessClassifier\": \"Modelo: Proceso gaussiano para clasificación.\\nOptimización: max log-verosimilitud marginal.\",\n",
        "    \"DeepLearning\": \"Modelo: Redes neuronales profundas.\\nOptimización: min pérdida (e.g., cross-entropy).\"\n",
        "}\n",
        "\n",
        "def generate_pca_plot(_X_pca, _y, _images):\n",
        "    \\\"\\\"\\\"Generates the PCA plot with representative images.\\\"\\\"\\\"\n",
        "    fig = px.scatter(x=_X_pca[:, 0], y=_X_pca[:, 1], color=_y, labels={'x': 'PC1', 'y': 'PC2'}, title=\"Proyección PCA\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_pca[idx, 0], y=_X_pca[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "def generate_umap_plot(_X_umap, _y, _images, n_neighbors):\n",
        "    \\\"\\\"\\\"Generates the UMAP plot with representative images for a given number of neighbors.\\\"\\\"\\\"\n",
        "    fig = px.scatter(x=_X_umap[:, 0], y=_X_umap[:, 1], color=_y, labels={'x': 'UMAP1', 'y': 'UMAP2'}, title=f\"Proyección UMAP (n_neighbors={n_neighbors})\")\n",
        "    for i in range(10):\n",
        "        idx = np.where(_y == i)[0][0]\n",
        "        img = _images[idx]\n",
        "        img_pil = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        buffered = BytesIO()\n",
        "        img_pil.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "        fig.add_layout_image(\n",
        "            dict(\n",
        "                source=f\"data:image/png;base64,{img_str}\",\n",
        "                x=_X_umap[idx, 0], y=_X_umap[idx, 1],\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                sizex=0.5, sizey=0.5,\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def generate_classifier_results(classifier, _report_lr, _report_rf, _report_cnn, _fpr_lr, _tpr_lr, _roc_auc_lr, _fpr_rf, _tpr_rf, _roc_auc_rf, _fpr_cnn, _tpr_cnn, _roc_auc_cnn):\n",
        "    \\\"\\\"\\\"Generates the metrics table and ROC plot for a given classifier.\\\"\\\"\\\"\n",
        "    if classifier == 'Logistic Regression':\n",
        "        report = _report_lr\n",
        "        fpr, tpr, roc_auc = _fpr_lr, _tpr_lr, _roc_auc_lr\n",
        "        title = \"Logistic Regression\"\n",
        "    elif classifier == 'Random Forest':\n",
        "        report = _report_rf\n",
        "        fpr, tpr, roc_auc = _fpr_rf, _tpr_rf, _roc_auc_rf\n",
        "        title = \"Random Forest\"\n",
        "    else: # CNN\n",
        "        report = _report_cnn\n",
        "        fpr, tpr, roc_auc = _fpr_cnn, _tpr_cnn, _roc_auc_cnn\n",
        "        title = \"CNN\"\n",
        "\n",
        "    # Create metrics table\n",
        "    metrics_html = \"<table>\"\n",
        "    metrics_html += \"<tr><td>Metric</td><td>Value</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>Accuracy</td><td>{report['accuracy']:.3f}</td></tr>\"\n",
        "    metrics_html += f\"<tr><td>F1-Score (macro)</td><td>{report['macro avg']['f1-score']:.3f}</td></tr>\"\n",
        "    metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "    # Create ROC curve\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.2f})'))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline', line=dict(dash='dash')))\n",
        "    fig.update_layout(title=f\"Curva ROC - {title}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
        "\n",
        "    return metrics_html, fig\n",
        "\n",
        "st.title(\"Dashboard Parcial 2: Teoría de Aprendizaje de Máquina\")\n",
        "\n",
        "# Sección teórica (punto a)\n",
        "st.header(\"Modelos y Optimización\")\n",
        "selected_model = st.selectbox(\n",
        "    \"Selecciona un modelo:\",\n",
        "    list(model_descriptions.keys())\n",
        ")\n",
        "st.markdown(model_descriptions[selected_model])\n",
        "\n",
        "# Proyecciones PCA y UMAP (punto b)\n",
        "st.header(\"Proyecciones del Conjunto USPS\")\n",
        "st.subheader(\"PCA\")\n",
        "# Perform PCA and display plot\n",
        "X_pca_updated, X_umap_initial = perform_dimensionality_reduction(X, 15) # Use default 15 for initial UMAP\n",
        "pca_fig = generate_pca_plot(X_pca_updated, y, images)\n",
        "st.plotly_chart(pca_fig)\n",
        "\n",
        "st.subheader(\"UMAP\")\n",
        "n_neighbors_umap = st.slider(\n",
        "    \"Número de vecinos para UMAP:\",\n",
        "    min_value=5,\n",
        "    max_value=50,\n",
        "    value=15,\n",
        "    step=1\n",
        ")\n",
        "# Perform UMAP with selected neighbors and display plot\n",
        "X_pca_updated, X_umap_updated = perform_dimensionality_reduction(X, n_neighbors_umap)\n",
        "umap_fig = generate_umap_plot(X_umap_updated, y, images, n_neighbors_umap)\n",
        "st.plotly_chart(umap_fig)\n",
        "\n",
        "\n",
        "# Resultados de clasificación (punto c)\n",
        "st.header(\"Resultado de Clasificación\")\n",
        "selected_classifier = st.selectbox(\n",
        "    \"Selecciona un clasificador:\",\n",
        "    ('Logistic Regression', 'Random Forest', 'CNN')\n",
        ")\n",
        "\n",
        "# Display classifier results\n",
        "metrics_html, roc_fig = generate_classifier_results(selected_classifier, report_lr, report_rf, report_cnn, fpr_lr, tpr_lr, roc_auc_lr, fpr_rf, tpr_rf, roc_auc_rf, fpr_cnn, tpr_cnn, roc_auc_cnn)\n",
        "st.markdown(metrics_html, unsafe_allow_html=True)\n",
        "st.plotly_chart(roc_fig)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"dashboard_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_script_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7861cfd8"
      },
      "source": [
        "Ahora que el script `dashboard_app.py` ha sido creado, puedes ejecutarlo usando el siguiente comando en la terminal de Colab (o en tu terminal local si has descargado el archivo):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e080b86e",
        "outputId": "deb2e22b-d2a2-4bf3-e7c5-63de52f35531"
      },
      "source": [
        "!pip install ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f7a93d4",
        "outputId": "dae1f9a5-3eea-4df2-89fd-5d161d5bfc8b"
      },
      "source": [
        "%%bash\n",
        "pip install ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ngrok in /usr/local/lib/python3.11/dist-packages (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc32fee7",
        "outputId": "62d61492-8234-4f1f-9946-7cfc52751236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "%%bash\n",
        "python -m streamlit run dashboard_app.py &"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-411841805.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python -m streamlit run dashboard_app.py &\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process is interrupted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}