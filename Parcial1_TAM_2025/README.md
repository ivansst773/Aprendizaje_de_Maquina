# Parcial 1 - Teor칤a de Aprendizaje de M치quina

## Estructura del repositorio
- `Parcial1_TAM_2025/Parte_Teorica/`: Contiene el PDF con las soluciones te칩ricas.
- `Parcial1_TAM_2025/Parte_Practica/`: Incluye el notebook `Punto_2_Modelos_Regresion.ipynb` con la implementaci칩n.
- `Parcial1_TAM_2025/dashboard_streamlit/`: Dashboard interactivo con los modelos.

## Ejecuci칩n local
```bash
# Instalar dependencias
pip install -r requirements.txt

# Lanzar el dashboard
streamlit run Parcial1_TAM_2025/dashboard_streamlit/app.py
```

## Visualizaci칩n en l칤nea

游녤 [Abrir Dashboard TAM - Ames Housing](https://aprendizajedemaquina-xkdhztxgv56qmmty6sdtfy.streamlit.app/)


## Datos utilizados

- **Dataset:** [Ames Housing Dataset en Kaggle](https://www.kaggle.com/datasets/shashanknecrothapa/ames-housing-dataset)

Este conjunto de datos contiene informaci칩n detallada sobre viviendas en Ames, Iowa, con m치s de 80 variables que describen caracter칤sticas f칤sicas, ubicaci칩n, calidad de construcci칩n, y m치s.  
Fue dise침ado como reemplazo del cl치sico Boston Housing Dataset para tareas de regresi칩n.

- **Tama침o:** ~2,900 registros
- **Variables destacadas:** `OverallQual`, `GrLivArea`, `GarageCars`, `YearBuilt`, `Neighborhood`, `SalePrice`
- **Objetivo:** Predecir el precio de venta (`SalePrice`) a partir de las dem치s caracter칤sticas

Este dataset es ideal para aplicar t칠cnicas de regresi칩n, ingenier칤a de caracter칤sticas, y evaluaci칩n de modelos.

游늷 Conclusiones y Recomendaciones
Este proyecto permiti칩 aplicar t칠cnicas de regresi칩n supervisada sobre el dataset Ames Housing, evaluando el desempe침o de tres modelos distintos:

Lasso Regression: 칰til para selecci칩n de variables, aunque puede subestimar precios altos.

Random Forest: mostr칩 buen desempe침o general, robusto ante ruido y no linealidades.

Gaussian Process Regression: ofrece predicciones suaves, pero es m치s costoso computacionalmente.

Recomendaciones para mejorar el modelo:
Realizar validaci칩n cruzada para obtener m칠tricas m치s robustas.

Aplicar ingenier칤a de caracter칤sticas sobre variables categ칩ricas como Neighborhood.

Probar modelos adicionales como XGBoost o LightGBM.

Implementar una secci칩n de interpretabilidad (SHAP, Permutation Importance) en el dashboard.
